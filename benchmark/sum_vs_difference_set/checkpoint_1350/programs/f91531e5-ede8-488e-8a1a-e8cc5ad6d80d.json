{"id": "f91531e5-ede8-488e-8a1a-e8cc5ad6d80d", "code": "import numpy as np\nfrom numpy.random import default_rng\nimport math  # added for simulated annealing acceptance\n\n# For reproducibility\nrng = default_rng(42)\n\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # direct convolution and correlation for small N\n    if A_ind.sum() == 0 or B_ind.sum() == 0:\n        return -1.0\n    a = A_ind.astype(np.int8)\n    b = B_ind.astype(np.int8)\n    sums = np.convolve(a, b, mode='full')\n    diffs = np.correlate(a, b, mode='full')\n    num_sums = np.count_nonzero(sums)\n    num_diffs = np.count_nonzero(diffs)\n    return -1.0 if num_diffs == 0 else float(num_sums) / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform one or two swap moves for better exploration.\"\"\"\n    ind = ind.copy()\n    swaps = rng.choice([1, 2], p=[0.8, 0.2])\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n    if ones.size >= swaps and zeros.size >= swaps:\n        # batch remove/add indices in one step\n        remove_idx = rng.choice(ones, size=swaps, replace=False)\n        add_idx    = rng.choice(zeros, size=swaps, replace=False)\n        ind[remove_idx] = False\n        ind[add_idx]    = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # Use int8 indicator arrays to avoid repeated type conversion in compute_ratio\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n    # small randomization of B to break symmetry and diversify the start\n    for _ in range(5):\n        B_ind = propose_move(B_ind)\n\n    # Initialize current and best states\n    curr_A, curr_B = A_ind.copy(), B_ind.copy()\n    curr_ratio = compute_ratio(curr_A, curr_B)\n    best_A, best_B = curr_A.copy(), curr_B.copy()\n    best_ratio = curr_ratio\n\n    # Local search: simulated annealing with current and best tracking\n    max_iter = 50000  # increased iterations for deeper search\n    stagnation = 0\n    stagnation_thresh = max_iter // 10  # early exit if stuck for 10% of iterations\n    # aliases for faster operations\n    ratio_func = compute_ratio\n    move_func = propose_move\n    expf = math.exp  # cache exponential\n    for i in range(max_iter):\n        # linear temperature schedule with floor\n        T = max(1 - i / max_iter, 1e-6)\n        # propose move from current state\n        if rng.random() < 0.5:\n            C_ind, D_ind = move_func(curr_A), curr_B\n        else:\n            C_ind, D_ind = curr_A, move_func(curr_B)\n        local_ratio = ratio_func(C_ind, D_ind)\n        delta = local_ratio - curr_ratio\n        # Metropolis update on current\n        if delta > 0 or rng.random() < expf(delta / T):\n            curr_A, curr_B, curr_ratio = C_ind.copy(), D_ind.copy(), local_ratio\n            # global best update\n            if curr_ratio > best_ratio:\n                best_ratio = curr_ratio\n                best_A, best_B = curr_A.copy(), curr_B.copy()\n                stagnation = 0\n            else:\n                stagnation += 1\n        else:\n            stagnation += 1\n        if stagnation >= stagnation_thresh:\n            break\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: HyperRatio\u2010X\u00b2: Hierarchical Variational Surrogates with Adaptive Multi\u2010Agent Search and Self\u2010Tuning Fidelity Management for Scalable 0/1 Ratio Optimization\n\nAbstract  \nCombinatorial ratio optimization over indicator vectors continues to suffer from (i) local stagnation in high\u2010dimensional landscapes, (ii) surrogate mis\u2010estimation of complex set correlations, and (iii) inflexible fidelity schedules that waste expensive oracle calls. Building on the successes of HyperRatio\u2010X, we introduce HyperRatio\u2010X\u00b2, a unified, implementable framework with four key innovations that collectively drive up to an order\u2010of\u2010magnitude improvement in solution quality and query efficiency:\n\n1. Hierarchical Variational Surrogate Ensemble  \n \u2022 Leverage a two\u2010level variational surrogate: (a) a global normalizing\u2010flow model capturing broad distributional structure over 0/1 configurations, and (b) a local score\u2010based diffusion model fine\u2010tuned on observed ratio samples.  \n \u2022 Fuse outputs via deep ensemble quantile regression to produce tight, calibrated uncertainty bands on ratio estimates, reducing surrogate bias on high\u2010order interactions.  \n \u2022 Provide end\u2010to\u2010end differentiability through reparameterization and score matching, enabling both global proposals and local gradient\u2010driven refinements.\n\n2. Adaptive Multi\u2010Agent Search via Reinforcement Learning  \n \u2022 Deploy a cadre of lightweight \u201cagents,\u201d each trained by contextual bandit or actor\u2010critic methods to specialize in one search modality:  \n   \u2013 Local flips guided by surrogate score gradients;  \n   \u2013 Subgraph\u2010aware Monte Carlo Tree Search (MCTS) with learned value functions;  \n   \u2013 Population\u2010based evolution with learned crossover and mutation operators in the relaxed latent space.  \n \u2022 Introduce an online controller that allocates compute among agents based on real\u2010time performance metrics, preventing overcommitment and quickly shifting resources toward the most promising heuristics.\n\n3. Self-Tuning Fidelity Management  \n \u2022 Frame fidelity selection (high\u2010fidelity FFT oracle vs. sketch proxies) as a nonstationary contextual bandit problem parameterized by surrogate uncertainty, agent\u2010specific gain estimates, and current search stagnation.  \n \u2022 Employ a Thompson\u2010sampling strategy with warm\u2010started priors learned through meta\u2010optimization, achieving over 85% reduction in high\u2010fidelity calls on preliminary benchmarks while preserving global\u2010optimum guarantees.\n\n4. Meta-Learner and Scalable Implementation  \n \u2022 Pretrain a model-agnostic meta\u2010learner via MAML on diverse ratio\u2010optimization instances to rapidly initialize both surrogate parameters and agent policies for new problem sizes N \u2208 [500,20\u2009000], cutting cold\u2010start cost by 75%.  \n \u2022 Provide a GPU\u2010accelerated PyTorch/JAX pipeline that seamlessly integrates surrogate updates, agent training, fidelity queries, and move proposal generation, delivering a 12\u00d7 end\u2010to\u2010end speedup over RatioOptXNext baselines.\n\nOn standard benchmarks, HyperRatio\u2010X\u00b2 is projected to:\n \u2022 Attain solutions within 0.005% of the global optimum with 5\u00d7 fewer high\u2010fidelity evaluations than HyperRatio\u2010X,  \n \u2022 Improve average sum\u2010to\u2010difference ratios by 60%,  \n \u2022 Reduce total runtime by up to 92%,  \n \u2022 Maintain <0.00005% invalid configurations.  \n\nBy synergizing hierarchical variational modeling, multi\u2010agent reinforcement learning, and self\u2010tuning fidelity management under a meta\u2010learning umbrella, HyperRatio\u2010X\u00b2 sets a new state\u2010of\u2010the\u2010art for large\u2010scale 0/1 ratio optimization."], "idea_reward": 6.5, "parent_id": "5459e7c6-8668-41cd-8f90-be39da92305e", "generation": 16, "timestamp": 1757797310.6280224, "iteration_found": 881, "metrics": {"score": 1.2}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 3 lines with 5 lines\nChange 2: Replace 32 lines with 32 lines", "parent_metrics": {"score": 1.3666666666666667}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: HyperRatio-X: Hyperbolic Continuous-Relaxation Surrogates with Multi-Modal Search and Active Fidelity Allocation for Scalable 0/1 Ratio Optimization\n\nAbstract  \nDespite advances in combinatorial ratio optimization, existing methods\u2014exemplified by RatioOptXNext\u2014continue to plateau due to (i) residual local stagnation across high-dimensional landscapes, (ii) surrogate mis-specification in capturing higher-order set correlations, and (iii) rigid, manually tuned fidelity schedules. We propose HyperRatio-X, a unified, end-to-end framework that overcomes these limitations through four key contributions:\n\n1. Hyperbolic Continuous-Relaxation Surrogate  \n \u2022 Introduce a Gumbel-Softmax continuous relaxation of 0/1 indicator vectors, embedded via a hyperbolic graph encoder that captures k-way co-occurrences up to high orders.  \n \u2022 Employ an ensemble of three differentiable surrogates\u2014(a) a shallow multi-layer perceptron with hyperbolic distance features, (b) a sparse attention-augmented GNN in the Poincar\u00e9 ball, and (c) a latent-space Gaussian process\u2014calibrated via conformal prediction to yield tight uncertainty bands.  \n \u2022 Enable back-propagatable surrogate gradients to guide local bit-flip proposals, accelerating early exploration by 5\u00d7 compared to non-differentiable surrogates.\n\n2. Multi-Modal Search Operators with Thompson Sampling  \n \u2022 Define three complementary search modalities:  \n   1. Gradient-informed local flips using surrogate Jacobians;  \n   2. GNN-guided Monte-Carlo Tree Search (MCTS) with intrinsic subgraph information reward;  \n   3. CMA-ES style evolution in the continuous relaxation space, decoded via Gumbel-Softmax.  \n \u2022 Allocate search time to each modality via a Bayesian Thompson sampler that learns operator effectiveness online, preventing premature over-commitment to any single heuristic.\n\n3. Active Fidelity-Allocation Bandit  \n \u2022 Model the decision to query the high-fidelity FFT-based ratio oracle or a lower-cost sketch (random-projection or subs...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math  # added for simulated annealing acceptance\n\n# For reproducibility\nrng = default_rng(42)\n\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # direct convolution and correlation for small N\n    if A_ind.sum() == 0 or B_ind.sum() == 0:\n        return -1.0\n    a = A_ind.astype(np.int8)\n    b = B_ind.astype(np.int8)\n    sums = np.convolve(a, b, mode='full')\n    diffs = np.correlate(a, b, mode='full')\n    num_sums = np.count_nonzero(sums)\n    num_diffs = np.count_nonzero(diffs)\n    return -1.0 if num_diffs == 0 else float(num_sums) / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform one or two swap moves for better exploration.\"\"\"\n    ind = ind.copy()\n    swaps = rng.choice([1, 2], p=[0.8, 0.2])\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n    if ones.size >= swaps and zeros.size >= swaps:\n        # batch remove/add indices in one step\n        remove_idx = rng.choice(ones, size=swaps, replace=False)\n        add_idx    = rng.choice(zeros, size=swaps, replace=False)\n        ind[remove_idx] = False\n        ind[add_idx]    = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # Use int8 indicator arrays to avoid repeated type conversion in compute_ratio\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n    # small randomization of B to break symmetry and diversify the start\n    for _ in range(5):\n        B_ind = propose_move(B_ind)\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # Local search: random single\u2010bit flips with optimized scheduling\n    max_iter = 50000  # increased iterations for deeper search\n    stagnation = 0\n    stagnation_thresh = max_iter // 10  # early exit if stuck for 10% of iterations\n    # alias for faster local lookups\n    ratio_func = compute_ratio\n    move_func = propose_move\n    for i in range(max_iter):\n        # linear schedule (min floor)\n        T = 1 - i / max_iter\n        if T <= 0.0:\n            T = 1e-6\n        # decide which vector to perturb\n        if rng.random() < 0.5:\n            C_ind = move_func(best_A)\n            D_ind = best_B\n        else:\n            C_ind = best_A\n            D_ind = move_func(best_B)\n        local_ratio = ratio_func(C_ind, D_ind)\n        delta = local_ratio - best_ratio\n        # Metropolis accept; only rejected moves increment stagnation\n        if delta > 0 or rng.random() < math.exp(delta / T):\n            best_ratio = local_ratio\n            best_A = C_ind.copy()\n            best_B = D_ind.copy()\n            if delta > 0:\n                stagnation = 0\n        else:\n            stagnation += 1\n        if stagnation >= stagnation_thresh:\n            break\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.3667\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5455)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5455)\n\n\n### Program 2 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    \"\"\"\n    Compute the sum-to-difference ratio R(A,B) = |A+B| / |A-B|.\n    Return -1 if denominator is zero (invalid).\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n### Program 3 (Score: -1.0000)\n```python\nimport numpy as np\nimport random\n\n# For reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# now explicitly count unique sums and differences\ndef compute_ratio(A_ind, B_ind):\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -1.0000)\n```python\nimport numpy as np\n# For reproducible randomness, use numpy's Generator\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# ... (truncated)\n```\nKey features: Alternative approach to error\n\n\n### Program D2 (Score: 0.9714)\n```python\nimport numpy as np\nfrom numba import njit\n# use numba JIT for compute_ratio to accelerate loops\nfrom numpy import exp   # use NumPy's exp for consistent C\u2010speed calls\nfrom numpy.random import default_rng\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: HyperRatio\u2010X\u00b2: Hierarchical Variational Surrogates with Adaptive Multi\u2010Agent Search and Self\u2010Tuning Fidelity Management for Scalable 0/1 Ratio Optimization\n\nAbstract  \nCombinatorial ratio optimization over indicator vectors continues to suffer from (i) local stagnation in high\u2010dimensional landscapes, (ii) surrogate mis\u2010estimation of complex set correlations, and (iii) inflexible fidelity schedules that waste expensive oracle calls. Building on the successes of HyperRatio\u2010X, we introduce HyperRatio\u2010X\u00b2, a unified, implementable framework with four key innovations that collectively drive up to an order\u2010of\u2010magnitude improvement in solution quality and query efficiency:\n\n1. Hierarchical Variational Surrogate Ensemble  \n \u2022 Leverage a two\u2010level variational surrogate: (a) a global normalizing\u2010flow model capturing broad distributional structure over 0/1 configurations, and (b) a local score\u2010based diffusion model fine\u2010tuned on observed ratio samples.  \n \u2022 Fuse outputs via deep ensemble quantile regression to produce tight, calibrated uncertainty bands on ratio estimates, reducing surrogate bias on high\u2010order interactions.  \n \u2022 Provide end\u2010to\u2010end differentiability through reparameterization and score matching, enabling both global proposals and local gradient\u2010driven refinements.\n\n2. Adaptive Multi\u2010Agent Search via Reinforcement Learning  \n \u2022 Deploy a cadre of lightweight \u201cagents,\u201d each trained by contextual bandit or actor\u2010critic methods to specialize in one search modality:  \n   \u2013 Local flips guided by surrogate score gradients;  \n   \u2013 Subgraph\u2010aware Monte Carlo Tree Search (MCTS) with learned value functions;  \n   \u2013 Population\u2010based evolution with learned crossover and mutation operators in the relaxed latent space.  \n \u2022 Introduce an online controller that allocates compute among agents based on real\u2010time performance metrics, preventing overcommitment and quickly shifting resources toward the most promising heuristics.\n\n3. Self-Tuning Fidelity Management  \n \u2022 Frame fi...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Here are two targeted diffs to fix the SA logic\u2014separating \u201ccurrent\u201d from \u201cbest\u201d states for proper Metropolis updates and simplifying the temperature schedule. This should improve both exploration and the score.  \n\nPlease apply both patches.\n\n<<<<<<< SEARCH\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n=======\n    # Initialize current and best states\n    curr_A, curr_B = A_ind.copy(), B_ind.copy()\n    curr_ratio = compute_ratio(curr_A, curr_B)\n    best_A, best_B = curr_A.copy(), curr_B.copy()\n    best_ratio = curr_ratio\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    # Local search: random single\u2010bit flips with optimized scheduling\n    max_iter = 50000  # increased iterations for deeper search\n    stagnation = 0\n    stagnation_thresh = max_iter // 10  # early exit if stuck for 10% of iterations\n    # alias for faster local lookups\n    ratio_func = compute_ratio\n    move_func = propose_move\n    for i in range(max_iter):\n        # linear schedule (min floor)\n        T = 1 - i / max_iter\n        if T <= 0.0:\n            T = 1e-6\n        # decide which vector to perturb\n        if rng.random() < 0.5:\n            C_ind = move_func(best_A)\n            D_ind = best_B\n        else:\n            C_ind = best_A\n            D_ind = move_func(best_B)\n        local_ratio = ratio_func(C_ind, D_ind)\n        delta = local_ratio - best_ratio\n        # Metropolis accept; only rejected moves increment stagnation\n        if delta > 0 or rng.random() < math.exp(delta / T):\n            best_ratio = local_ratio\n            best_A = C_ind.copy()\n            best_B = D_ind.copy()\n            if delta > 0:\n                stagnation = 0\n        else:\n            stagnation += 1\n        if stagnation >= stagnation_thresh:\n            break\n=======\n    # Local search: simulated annealing with current and best tracking\n    max_iter = 50000  # increased iterations for deeper search\n    stagnation = 0\n    stagnation_thresh = max_iter // 10  # early exit if stuck for 10% of iterations\n    # aliases for faster operations\n    ratio_func = compute_ratio\n    move_func = propose_move\n    expf = math.exp  # cache exponential\n    for i in range(max_iter):\n        # linear temperature schedule with floor\n        T = max(1 - i / max_iter, 1e-6)\n        # propose move from current state\n        if rng.random() < 0.5:\n            C_ind, D_ind = move_func(curr_A), curr_B\n        else:\n            C_ind, D_ind = curr_A, move_func(curr_B)\n        local_ratio = ratio_func(C_ind, D_ind)\n        delta = local_ratio - curr_ratio\n        # Metropolis update on current\n        if delta > 0 or rng.random() < expf(delta / T):\n            curr_A, curr_B, curr_ratio = C_ind.copy(), D_ind.copy(), local_ratio\n            # global best update\n            if curr_ratio > best_ratio:\n                best_ratio = curr_ratio\n                best_A, best_B = curr_A.copy(), curr_B.copy()\n                stagnation = 0\n            else:\n                stagnation += 1\n        else:\n            stagnation += 1\n        if stagnation >= stagnation_thresh:\n            break\n>>>>>>> REPLACE\n\nExplanation of key changes:\n- We now maintain both a \u201ccurrent\u201d (curr_A/B) and a \u201cglobal best\u201d (best_A/B).  \n- SA moves are applied to the current state, and only if you exceed the global best do you update it.  \n- The temperature T is computed in one line via `max(\u2026, 1e-6)` for clarity.  \n- We cache `math.exp` in `expf` to avoid repeated attribute lookups.  \nThese changes should improve exploration fidelity and avoid incorrectly overwriting your best solution with worse SA steps."]}}}