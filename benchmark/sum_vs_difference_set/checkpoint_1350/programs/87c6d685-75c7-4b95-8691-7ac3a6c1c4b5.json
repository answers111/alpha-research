{"id": "87c6d685-75c7-4b95-8691-7ac3a6c1c4b5", "code": "import numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    # use prebound functions to reduce attribute lookups\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = flatnonzero_fn(ind)\n    zeros = flatnonzero_fn(1 - ind)\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = 0\n            ind[adds] = 1\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = 0\n            ind[i_add] = 1\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 5   # smaller batch for faster per\u2010iteration time, more total iterations\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # Local bindings for performance\n    rng_random_local = rng_random\n    exp_local       = exp\n    propose_local   = propose_move\n    compute_local   = compute_ratio\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 5.0\n    decay = 0.9995        # faster cooling after an initial high\u2010temperature phase\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Copy only the vector we actually mutate\n            if rng_random_local() < 0.5:\n                C_ind = current_A.copy()\n                D_ind = current_B\n                C_ind = propose_local(C_ind)\n            else:\n                C_ind = current_A\n                D_ind = current_B.copy()\n                D_ind = propose_local(D_ind)\n            ratio = compute_local(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or rng_random_local() < exp_local(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: EquiGFlow-OPT: Equivariant GFlowNet-Augmented Differentiable Optimization with Meta-Adaptive Multi-Fidelity Surrogates for Sum-to-Difference Ratio Maximization\n\nAbstract  \nDespite recent progress in Graph-Guided Differentiable Relaxation and Policy Learning (GraDiM), current methods still plateau near a 1.53 ratio on N=30 benchmarks\u2014reflecting myopic proposal distributions, surrogate drift across scales, and inefficient fidelity scheduling. We introduce EquiGFlow-OPT, a unified framework that addresses these shortcomings with four novel contributions:\n\n1. Equivariant GFlowNet Sampler  \n  \u2022 We build a permutation-equivariant GFlowNet that learns a generative policy over set-pair configurations, sampling diverse high-ratio candidates in a single forward pass.  \n  \u2022 By framing each multi-bit move as a trajectory in a hypergraph state-space, we recover both global structure and auxiliary density estimation, overcoming local trap avoidance.\n\n2. Meta-Adaptive Multi-Fidelity Surrogate  \n  \u2022 We replace static Gaussian processes with a lightweight graph-transformer surrogate whose fidelity is controlled by a meta-learner.  \n  \u2022 The meta-learner adjusts the surrogate\u2019s depth and Gumbel-Softmax temperature online via gradient-based utility maximization, ensuring tight approximations where they matter most.\n\n3. Contrastive Self-Supervised Pretraining  \n  \u2022 To mitigate surrogate drift on larger N, we introduce a contrastive loss that pretrains the transformer on synthetic pairs of near-optimal and random configurations.  \n  \u2022 This regularization enforces smooth embeddings across Hamming neighborhoods, yielding more reliable gradient signals during fine-tuning.\n\n4. Adaptive Parallel Tempering with Exchange Policies  \n  \u2022 We orchestrate multiple annealed replicas of EquiGFlow policies across a temperature ladder, with learned graph-attention exchange proposals to swap configurations efficiently.  \n  \u2022 This dynamic coupling significantly enhances mixing, reducing stagnation in local optima.\n\nImplementation & Expected Impact  \nEquiGFlow-OPT is implemented in JAX for surrogate and meta-learner modules and in PyTorch for GFlowNet training, orchestrated via Ray RLlib for distributed parallel tempering. On N=30 and N=50 benchmarks, we anticipate surpassing ratios of 2.5 and scaling robustly to N=100 with less than 15% of the exact\u2010evaluation budget. Our open-source release will offer a high-performance toolkit for a broad class of discrete ratio-maximization and combinatorial-generation problems."], "idea_reward": 6.0, "parent_id": "b105a8c9-2336-4293-a6c4-0e30baaf0400", "generation": 19, "timestamp": 1757807728.86065, "iteration_found": 1066, "metrics": {"score": 1.4827586206896552}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 2 lines\nChange 2: 'BATCH_SIZE = 10  # optimized batch size for balanced exploration and computation' to 'BATCH_SIZE = 5   # smaller batch for faster per\u2010iteration time, more total iterations'\nChange 3: Replace 2 lines with 2 lines", "parent_metrics": {"score": 1.5161290322580645}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: Graph\u2010Guided Differentiable Relaxation and Multi\u2010Fidelity Policy Learning for Extremal Sum\u2010to\u2010Difference Ratio Maximization\n\nAbstract  \nExisting hill\u2010climbing and surrogate\u2010based meta\u2010optimizers for extremal sum\u2010to\u2010difference ratio maximization stagnate near 1.53 on N=30 instances, primarily due to (i) myopic local moves that ignore global structure, (ii) static surrogates unable to capture multi\u2010scale interactions, and (iii) the absence of usable gradient information in a purely discrete search. We propose a novel, modular pipeline\u2014Graph\u2010Guided Differentiable Relaxation and Multi\u2010Fidelity Policy Learning (GraDiM)\u2014that overcomes these limitations through four key advances:\n\n1. Hierarchical Graph Surrogate with Continuous Relaxation  \n \u2022 A hypergraph transformer encodes sets A and B as nodes and hyperedges, learning multi\u2010scale interactions via self\u2010attention.  \n \u2022 We introduce a smooth Gumbel\u2010Softmax relaxation of the sum\u2010to\u2010difference ratio, enabling implicit differentiation through the surrogate network and providing informative gradient signals for move proposals.\n\n2. Reinforcement\u2010Learning\u2010Driven Multi\u2010Bit Proposal Policy  \n \u2022 A graph attention policy network is trained via proximal policy optimization (PPO) to propose k\u2010bit reconfiguration moves.  \n \u2022 The policy leverages gradients from the relaxed surrogate as an auxiliary reward, biasing exploration toward globally promising patterns and overcoming the myopic behavior of random swaps.\n\n3. Multi\u2010Fidelity Bayesian Scheduler  \n \u2022 We deploy a Gaussian\u2010Process\u2010based bandit to allocate compute dynamically among (a) fast surrogate evaluations, (b) medium\u2010cost relaxed\u2010objective rollouts, and (c) exact ratio computations.  \n \u2022 This scheduler learns to reduce expensive exact calls by over 85% while preserving solution quality.\n\n4. Coarse\u2010to\u2010Fine Curriculum and Transfer  \n \u2022 Training proceeds on ascending N={30,50,80,120} problems, transferring learned surrogate weights, policy parameters, and scheduler hyperprio...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    # use prebound functions to reduce attribute lookups\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = flatnonzero_fn(ind)\n    zeros = flatnonzero_fn(1 - ind)\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = 0\n            ind[adds] = 1\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = 0\n            ind[i_add] = 1\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 10  # optimized batch size for balanced exploration and computation\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # Local bindings for performance\n    rng_random_local = rng_random\n    exp_local       = exp\n    propose_local   = propose_move\n    compute_local   = compute_ratio\n    A_ind = np.zeros(N, dtype=np.int8)\n    B_ind = np.zeros(N, dtype=np.int8)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9999        # slower cooling for broader exploration\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Copy only the vector we actually mutate\n            if rng_random_local() < 0.5:\n                C_ind = current_A.copy()\n                D_ind = current_B\n                C_ind = propose_local(C_ind)\n            else:\n                C_ind = current_A\n                D_ind = current_B.copy()\n                D_ind = propose_local(D_ind)\n            ratio = compute_local(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or rng_random_local() < exp_local(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.5161\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: 1.3571)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# For reproducibility\nrng = default_rng(42)\nrand = rng.random\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.3571)\n\n\n### Program 3 (Score: 0.7692)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nfrom numpy import correlate\n# Removed unused FFT imports for direct correlation path\n\n# For reproducibility\nrng = default_rng(42)\n# Cache computed ratios to avoid redundant computations\nratio_cache = {}\n\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (0.7692)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.0800)\n```python\nimport numpy as np\nfrom numba import njit\nfrom math import exp\nfrom numpy.random import default_rng\n\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.4138)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: EquiGFlow-OPT: Equivariant GFlowNet-Augmented Differentiable Optimization with Meta-Adaptive Multi-Fidelity Surrogates for Sum-to-Difference Ratio Maximization\n\nAbstract  \nDespite recent progress in Graph-Guided Differentiable Relaxation and Policy Learning (GraDiM), current methods still plateau near a 1.53 ratio on N=30 benchmarks\u2014reflecting myopic proposal distributions, surrogate drift across scales, and inefficient fidelity scheduling. We introduce EquiGFlow-OPT, a unified framework that addresses these shortcomings with four novel contributions:\n\n1. Equivariant GFlowNet Sampler  \n  \u2022 We build a permutation-equivariant GFlowNet that learns a generative policy over set-pair configurations, sampling diverse high-ratio candidates in a single forward pass.  \n  \u2022 By framing each multi-bit move as a trajectory in a hypergraph state-space, we recover both global structure and auxiliary density estimation, overcoming local trap avoidance.\n\n2. Meta-Adaptive Multi-Fidelity Surrogate  \n  \u2022 We replace static Gaussian processes with a lightweight graph-transformer surrogate whose fidelity is controlled by a meta-learner.  \n  \u2022 The meta-learner adjusts the surrogate\u2019s depth and Gumbel-Softmax temperature online via gradient-based utility maximization, ensuring tight approximations where they matter most.\n\n3. Contrastive Self-Supervised Pretraining  \n  \u2022 To mitigate surrogate drift on larger N, we introduce a contrastive loss that pretrains the transformer on synthetic pairs of near-optimal and random configurations.  \n  \u2022 This regularization enforces smooth embeddings across Hamming neighborhoods, yielding more reliable gradient signals during fine-tuning.\n\n4. Adaptive Parallel Tempering with Exchange Policies  \n  \u2022 We orchestrate multiple annealed replicas of EquiGFlow policies across a temperature ladder, with learned graph-attention exchange proposals to swap configurations efficiently.  \n  \u2022 This dynamic coupling significantly enhances mixing, reducing stagnation ...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Below are a few targeted edits that you can try to boost exploration early on, speed up per\u2010iteration work, and reduce array\u2010overhead.  Each change is presented as an exact SEARCH/REPLACE diff.\n\n1) Switch your indicator arrays to boolean.  This reduces memory and often speeds up bit\u2010wise ops:\n\n<<<<<<< SEARCH\n    A_ind = np.zeros(N, dtype=np.int8)\n    B_ind = np.zeros(N, dtype=np.int8)\n=======\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n>>>>>>> REPLACE\n\n2) Reduce the per\u2010iteration batch size so each outer loop gobbles less time\u2014allowing you to run more total iterations in the same budget:\n\n<<<<<<< SEARCH\nBATCH_SIZE = 10  # optimized batch size for balanced exploration and computation\n=======\nBATCH_SIZE = 5   # smaller batch for faster per\u2010iteration time, more total iterations\n>>>>>>> REPLACE\n\n3) Give the annealer a bit more \u201ckick\u201d up front\u2014and then cool more quickly\u2014so you both explore aggressively early and focus in sooner once you\u2019ve seen high\u2010ratio seeds:\n\n<<<<<<< SEARCH\n    T = 1.0\n    decay = 0.9999        # slower cooling for broader exploration\n=======\n    T = 5.0\n    decay = 0.9995        # faster cooling after an initial high\u2010temperature phase\n>>>>>>> REPLACE\n\nExplanation of rationale:\n\n- Boolean arrays cut down on unnecessary integer storage and can make convolution/correlation slightly faster.  \n- A smaller BATCH_SIZE speeds up each inner loop, effectively giving you more simulated\u2010annealing steps in a fixed time.  \n- Raising the starting temperature to 5.0 broadens your initial search, and a slightly smaller decay (0.9995) shifts you more quickly into a greedier regime once promising candidates are found."]}}}