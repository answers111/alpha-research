{"id": "01b504f9-b84a-4c04-87dc-c4c5f378ef33", "code": "import numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Removed caching to reduce per\u2010call overhead\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check for empty sets\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    return -1.0 if num_diffs == 0 else num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray, ones: np.ndarray, zeros: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move using precomputed one- and zero-indices.\"\"\"\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # use boolean arrays for lighter\u2010weight, faster bit\u2010ops\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    # Initialize counters for adaptive temperature control\n    no_improve = 0\n    plateau_limit = 5000  # iterations to trigger a temperature boost\n    decay = 0.9999        # even slower cooling to escape local optima\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    # Pre-bind heavy functions once per outer loop\n    _compute_ratio = compute_ratio\n    _rand        = rng_random\n    _exp         = exp\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        # Precompute indices once per outer iteration\n        ones_A = flatnonzero_fn(current_A)\n        zeros_A = flatnonzero_fn(~current_A)\n        ones_B = flatnonzero_fn(current_B)\n        zeros_B = flatnonzero_fn(~current_B)\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n            else:\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or _rand() < _exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best and manage no\u2010improvement counter\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n            no_improve = 0\n        else:\n            no_improve += 1\n        # adaptive temperature boost when stuck\n        if no_improve > plateau_limit:\n            T *= 1.5       # momentarily increase T to escape plateau\n            no_improve = 0\n        # regular cooldown\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: A Hierarchical Surrogate\u2010Assisted Deep\u2010Reinforcement Evolutionary Framework for Optimizing Sum-to-Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address three key limitations of existing hill-climbing and simulated-annealing based searches for maximizing |A+B|/|A\u2212B| over binary indicator pairs\u2014plateaued convergence (~1.5455), entrapment in local optima, and high per-evaluation cost\u2014by integrating advances from surrogate modeling, deep reinforcement learning, and population-based heuristics into a unified, easily\u2010implementable pipeline. Our contributions are:\n\n1. Graph-Structured Surrogate Model  \n \u2022 Replace summary-statistic regressors with a lightweight graph neural network (GNN) that directly ingests bit-vector adjacency and interaction graphs to predict both global ratio improvements and per-bit \u201cimpact scores.\u201d  \n \u2022 Pre-train the surrogate on a diverse archive of labeled proposals, then fine-tune online to maintain 90% prediction accuracy on new candidate moves.  \n \u2022 Use top-K filtering to achieve a 5\u00d7 reduction in exact GPU-accelerated convolution/correlation calls.\n\n2. Multi-Population Evolution with Adaptive Operator Learning  \n \u2022 Launch parallel subpopulations combining evolutionary strategies (CMA-ES, differential evolution, multi-swap hill-climbing) to promote diverse search trajectories.  \n \u2022 Employ a meta-learner based on contextual Thompson sampling to allocate compute to the most promising subpopulations and mutation operators in real time.  \n \u2022 Periodically exchange elite individuals via structured migrations to prevent premature convergence.\n\n3. Deep Reinforcement Move Proposer  \n \u2022 Frame per-bit swap/add/remove selection as a Markov decision process and train a small policy network (two\u2010layer MLP) via Proximal Policy Optimization using surrogate feedback as a reward signal.  \n \u2022 Dynamically adjust mutation magnitudes (single\u2010bit up to block swaps) based on learned state embeddings, enabling both fine\u2010grained refinements and bold escapes from plateaus.\n\n4. Automated Temperature and Hyperparameter Control  \n \u2022 Substitute fixed cooling schedules with a self-tuning temperature controller that uses Shannon-entropy\u2013based diversity metrics to trigger reheating or restart events.  \n \u2022 Leverage Bayesian Optimization to tune key hyperparameters (batch size, migration interval, learning rates) in an outer loop under a fixed budget.\n\n5. End-to-End GPU Acceleration  \n \u2022 Port the evaluation and surrogate pipelines into JAX/Flax, harnessing XLA for fused convolution/correlation and mixed\u2010precision operations, yielding 8\u201312\u00d7 speedups for N\u226550.  \n \u2022 Orchestrate asynchronous batched evaluations via a lightweight Dask cluster interface, ensuring linear scaling across multi\u2010GPU systems.\n\nIn experiments over N=30\u2013500 indicator dimensions, our framework is expected to  \n (i) converge 3\u20135\u00d7 faster to ratios \u22651.8,  \n (ii) consistently surpass 1.85 final ratios under equal compute, and  \n (iii) demonstrate robust sublinear scaling on up to 8 GPUs.  \nWe outline a staged implementation: (1) graph-surrogate and policy network prototyping, (2) multi-population and meta-learner integration, (3) JAX/CUDA kernel optimization, and (4) comprehensive ablation and benchmarking. This design balances novelty with practical implementability, paving the way for reproducible, high\u2010performance combinatorial optimization in binary indicator spaces."], "idea_reward": 7.25, "parent_id": "b86f1b77-156e-41e9-82f5-c9e9c0b849b7", "generation": 21, "timestamp": 1757827345.4623427, "iteration_found": 1320, "metrics": {"score": 1.5454545454545454}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace T = 1.0 with 4 lines\nChange 2: Replace 5 lines with 12 lines", "parent_metrics": {"score": 1.5454545454545454}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: A Multi-Population Surrogate-Guided Evolutionary Framework with Learned Proposal Distributions for Maximizing Sum-to-Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address the sub-optimal convergence (score \u22481.5455), local-optima stagnation, and high per-evaluation cost of current hill-climbing and simulated-annealing methods for maximizing the sum-to-difference ratio |A+B|/|A\u2212B| over 0/1 indicator vectors. Building on recent successes in surrogate-assisted search, population diversity maintenance, and reinforcement learning for move proposals, we propose a novel, implementable framework that integrates:\n\n1. Surrogate-Accelerated Screening  \n   \u2022 Train a lightweight neural surrogate on summary statistics (marginal counts, auto- and cross-correlation histograms) to predict ratio improvements.  \n   \u2022 Use the surrogate to pre-filter large batches of candidate moves, evaluating only the top-K via exact GPU-accelerated convolution/correlation.\n\n2. Multi-Population Evolutionary Search  \n   \u2022 Maintain multiple subpopulations evolving in parallel under distinct operator policies (single-swap, multi-swap, block shuffle).  \n   \u2022 Employ a multi-armed bandit meta-controller to adaptively allocate compute budget to the most promising subpopulations and operators.  \n   \u2022 Periodically migrate elite individuals across subpopulations to enhance global exploration.\n\n3. Learned Proposal Distributions  \n   \u2022 Formulate mutation operator selection as a contextual bandit problem, using per-bit \u201cimportance scores\u201d learned via policy-gradient updates from surrogate feedback.  \n   \u2022 Bias swaps toward bit positions with historically high impact on ratio gains.\n\n4. Dynamic Temperature and Restart Mechanisms  \n   \u2022 Replace fixed cooling schedules with adaptive temperature control that increases temperature upon convergence plateaus, measured by population diversity metrics.  \n   \u2022 Trigger controlled random-restarts from elite archives to avoid deep local traps.\n\n5. GPU-Accelera...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Removed caching to reduce per\u2010call overhead\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check for empty sets\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    return -1.0 if num_diffs == 0 else num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray, ones: np.ndarray, zeros: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move using precomputed one- and zero-indices.\"\"\"\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # use boolean arrays for lighter\u2010weight, faster bit\u2010ops\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9999        # even slower cooling to escape local optima\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    # Pre-bind heavy functions once per outer loop\n    _compute_ratio = compute_ratio\n    _rand        = rng_random\n    _exp         = exp\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        # Precompute indices once per outer iteration\n        ones_A = flatnonzero_fn(current_A)\n        zeros_A = flatnonzero_fn(~current_A)\n        ones_B = flatnonzero_fn(current_B)\n        zeros_B = flatnonzero_fn(~current_B)\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n            else:\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or _rand() < _exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.5455\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: 1.1026)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math  # added for simulated annealing acceptance\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.1026)\n\n\n### Program 3 (Score: 1.2105)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.2105)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.0455)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.5455)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\nimport numpy.fft as fft_module\n# Pre\u2010bind exponential and initialize a cache for compute_ratio\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: A Hierarchical Surrogate\u2010Assisted Deep\u2010Reinforcement Evolutionary Framework for Optimizing Sum-to-Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address three key limitations of existing hill-climbing and simulated-annealing based searches for maximizing |A+B|/|A\u2212B| over binary indicator pairs\u2014plateaued convergence (~1.5455), entrapment in local optima, and high per-evaluation cost\u2014by integrating advances from surrogate modeling, deep reinforcement learning, and population-based heuristics into a unified, easily\u2010implementable pipeline. Our contributions are:\n\n1. Graph-Structured Surrogate Model  \n \u2022 Replace summary-statistic regressors with a lightweight graph neural network (GNN) that directly ingests bit-vector adjacency and interaction graphs to predict both global ratio improvements and per-bit \u201cimpact scores.\u201d  \n \u2022 Pre-train the surrogate on a diverse archive of labeled proposals, then fine-tune online to maintain 90% prediction accuracy on new candidate moves.  \n \u2022 Use top-K filtering to achieve a 5\u00d7 reduction in exact GPU-accelerated convolution/correlation calls.\n\n2. Multi-Population Evolution with Adaptive Operator Learning  \n \u2022 Launch parallel subpopulations combining evolutionary strategies (CMA-ES, differential evolution, multi-swap hill-climbing) to promote diverse search trajectories.  \n \u2022 Employ a meta-learner based on contextual Thompson sampling to allocate compute to the most promising subpopulations and mutation operators in real time.  \n \u2022 Periodically exchange elite individuals via structured migrations to prevent premature convergence.\n\n3. Deep Reinforcement Move Proposer  \n \u2022 Frame per-bit swap/add/remove selection as a Markov decision process and train a small policy network (two\u2010layer MLP) via Proximal Policy Optimization using surrogate feedback as a reward signal.  \n \u2022 Dynamically adjust mutation magnitudes (single\u2010bit up to block swaps) based on learned state embeddings, enabling both fine\u2010grained refinements and bold esc...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Here are two targeted diffs to add an **adaptive temperature boost** when the search plateaus. This should help the annealing process escape deep local optima and improve the final score, while keeping the change small and isolated:\n\n1) Initialize a no\u2010improvement counter right after you set up the temperature  \n2) In the main loop, track consecutive non\u2010improving iterations and temporarily raise T when you hit a plateau\n\n<<<<<<< SEARCH\n    T = 1.0\n=======\n    T = 1.0\n    # Initialize counters for adaptive temperature control\n    no_improve = 0\n    plateau_limit = 5000  # iterations to trigger a temperature boost\n>>>>>>> REPLACE\n\nand\n\n<<<<<<< SEARCH\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n=======\n        # update global best and manage no\u2010improvement counter\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n            no_improve = 0\n        else:\n            no_improve += 1\n        # adaptive temperature boost when stuck\n        if no_improve > plateau_limit:\n            T *= 1.5       # momentarily increase T to escape plateau\n            no_improve = 0\n        # regular cooldown\n        T *= decay\n>>>>>>> REPLACE\n\nExplanation:\n\n- We introduce `no_improve` to count consecutive iterations without improving the global best.\n- Once `no_improve` exceeds `plateau_limit`, we \u201cheat up\u201d the system (`T *= 1.5`), giving the simulated annealing a better chance to jump out of a flat region.\n- After the boost, we reset `no_improve` so that further boosts only happen if we plateau again.\n\nThis small tweak often leads to higher final ratios by avoiding deep local entrapment without significantly increasing per\u2010iteration cost."]}}}