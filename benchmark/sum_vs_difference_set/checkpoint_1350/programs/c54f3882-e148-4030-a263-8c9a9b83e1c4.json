{"id": "c54f3882-e148-4030-a263-8c9a9b83e1c4", "code": "import numpy as np\nfrom numpy.random import default_rng\n\n# Prebind convolution for performance\nconv = np.convolve\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        return -1.0\n    # sumset via convolution (bool\u2192int promotion)\n    sums_conv = conv(A_ind, B_ind)\n    num_sums = np.count_nonzero(sums_conv)\n    # diffset via convolution with reversed B\n    diffs_conv = conv(A_ind, B_ind[::-1])\n    num_diffs = np.count_nonzero(diffs_conv)\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Randomly add or remove one bit, ensuring at least one \u20181\u2019 remains.\"\"\"\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n    # if too few ones or by random choice, add\n    if zeros.size > 0 and (ones.size <= 1 or rng.random() < 0.5):\n        ind[rng.choice(zeros)] = True\n    # else remove (only if more than one one)\n    elif ones.size > 1:\n        ind[rng.choice(ones)] = False\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n        # propose a balanced add/remove move for A or B using helper\n        if rng.random() < 0.5:\n            C_ind = propose_move(C_ind)\n        else:\n            D_ind = propose_move(D_ind)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip invalid proposals immediately\n        if ratio < 0:\n            continue\n        if ratio > best_ratio:\n            best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: Hybrid Structural Metaheuristics for Enhanced MSTD Set Discovery\n\nAbstract:\nWe address the problem of discovering two binary indicator sets A, B \u2282 {0,\u2026,N\u22121} that maximize the sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|, a central question in the study of More Sums Than Differences (MSTD) sets. The prevailing hill\u2010climbing method, which randomly flips single bits while recalculating sum\u2010 and difference\u2010convolutions from scratch, achieves only a modest ratio (~1.2105 for N=30) and suffers from (1) entrapment in local optima, (2) quadratic\u2010time convolution costs, and (3) limited exploration of algebraic structure.\n\nWe propose a novel, implementable framework combining three key innovations:\n\n1. FFT\u2010Accelerated and Incremental Convolution:\n   \u2022 Replace direct np.convolve with FFT\u2010based convolution (e.g. using pyFFTW) to reduce each evaluation from O(N^2) to O(N log N).\n   \u2022 Develop an incremental update scheme that adjusts the counts of impacted sum\u2010 and difference\u2010pairs in O(1) time whenever a single bit flips, thereby accelerating inner\u2010loop evaluations by orders of magnitude.\n\n2. Hybrid Metaheuristic Search:\n   \u2022 Integrate simulated annealing with a light tabu\u2010search overlay to escape local traps, dynamically adjusting acceptance criteria for uphill moves.\n   \u2022 Embed a small genetic algorithm that maintains and recombines a population of candidate (A,B) pairs, employing structure\u2010preserving crossover (swapping contiguous blocks) and targeted mutation (balanced bit\u2010swaps) to explore diverse regions of the search space.\n   \u2022 Implement multi\u2010start restarts and asynchronous island migration (MPI or multiprocessing) to leverage parallel hardware and improve global search coverage.\n\n3. Algebraic Structural Seeding:\n   \u2022 Seed initial populations with known small MSTD constructions (e.g. Conway\u2019s 8\u2010element set) subjected to modular translations, dilations, and complement operations that provably preserve or improve the ratio.\n   \u2022 Generalize to higher\u2010order templates inspired by Sidon and sum\u2010free sets, injecting group\u2010theoretic diversity without sacrificing computational tractability.\n\nWe will validate our approach on benchmark values of N (30, 50, 100), comparing best\u2010found ratios, convergence speed, and computational cost against the baseline hill\u2010climber. Preliminary experiments indicate achievable ratios exceeding 1.25 for N=30 and robust scalability. Our open\u2010source implementation will facilitate further exploration of the rich combinatorial landscape of MSTD phenomena."], "idea_reward": 5.6, "parent_id": "e91bc0e2-58b1-48d3-91aa-9b3333b4455b_migrant_4_migrant_3", "generation": 8, "timestamp": 1757789029.6520875, "iteration_found": 657, "metrics": {"score": 1.2105263157894737}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 5 lines\nChange 2: Replace 6 lines with 6 lines\nChange 3: Replace 2 lines with 2 lines", "parent_metrics": {"score": 1.2105263157894737}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \n\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        return -1.0\n    # sumset via convolution\n    sums_conv = np.convolve(A_ind.astype(int), B_ind.astype(int))\n    num_sums = np.count_nonzero(sums_conv)\n    # diffset via convolution with reversed B\n    diffs_conv = np.convolve(A_ind.astype(int), B_ind[::-1].astype(int))\n    num_diffs = np.count_nonzero(diffs_conv)\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Randomly add or remove one bit, ensuring at least one \u20181\u2019 remains.\"\"\"\n    ones = np.nonzero(ind)[0]\n    zeros = np.nonzero(~ind)[0]\n    # if too few ones or by random choice, add\n    if zeros.size > 0 and (ones.size <= 1 or rng.random() < 0.5):\n        ind[rng.choice(zeros)] = True\n    # else remove (only if more than one one)\n    elif ones.size > 1:\n        ind[rng.choice(ones)] = False\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n        # propose a balanced add/remove move for A or B using helper\n        if rng.random() < 0.5:\n            C_ind = propose_move(C_ind)\n        else:\n            D_ind = propose_move(D_ind)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip invalid proposals immediately\n        if ratio < 0:\n            continue\n        if ratio > best_ratio:\n            best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.2105\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5161\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5161)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5161)\n\n\n### Program 2 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    S = np.convolve(A_ind, B_ind)\n    sizeS = np.count_nonzero(S)\n    D = np.convolve(A_ind, B_ind[::-1])\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n### Program 3 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    \"\"\"\n    Compute the sum-to-difference ratio R(A,B) = |A+B| / |A-B|.\n    Return -1 if denominator is zero (invalid).\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# ... (truncated)\n```\nKey features: Alternative approach to error\n\n\n### Program D2 (Score: 1.3000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n# Prebind convolution removed; replaced by set\u2010based operations for efficiency\n# convolve = np.convolve\n\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: Hybrid Structural Metaheuristics for Enhanced MSTD Set Discovery\n\nAbstract:\nWe address the problem of discovering two binary indicator sets A, B \u2282 {0,\u2026,N\u22121} that maximize the sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|, a central question in the study of More Sums Than Differences (MSTD) sets. The prevailing hill\u2010climbing method, which randomly flips single bits while recalculating sum\u2010 and difference\u2010convolutions from scratch, achieves only a modest ratio (~1.2105 for N=30) and suffers from (1) entrapment in local optima, (2) quadratic\u2010time convolution costs, and (3) limited exploration of algebraic structure.\n\nWe propose a novel, implementable framework combining three key innovations:\n\n1. FFT\u2010Accelerated and Incremental Convolution:\n   \u2022 Replace direct np.convolve with FFT\u2010based convolution (e.g. using pyFFTW) to reduce each evaluation from O(N^2) to O(N log N).\n   \u2022 Develop an incremental update scheme that adjusts the counts of impacted sum\u2010 and difference\u2010pairs in O(1) time whenever a single bit flips, thereby accelerating inner\u2010loop evaluations by orders of magnitude.\n\n2. Hybrid Metaheuristic Search:\n   \u2022 Integrate simulated annealing with a light tabu\u2010search overlay to escape local traps, dynamically adjusting acceptance criteria for uphill moves.\n   \u2022 Embed a small genetic algorithm that maintains and recombines a population of candidate (A,B) pairs, employing structure\u2010preserving crossover (swapping contiguous blocks) and targeted mutation (balanced bit\u2010swaps) to explore diverse regions of the search space.\n   \u2022 Implement multi\u2010start restarts and asynchronous island migration (MPI or multiprocessing) to leverage parallel hardware and improve global search coverage.\n\n3. Algebraic Structural Seeding:\n   \u2022 Seed initial populations with known small MSTD constructions (e.g. Conway\u2019s 8\u2010element set) subjected to modular translations, dilations, and complement operations that provably preserve or improve the ratio.\n   \u2022 Generalize to higher\u2010order templates inspired...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Here are three targeted diffs to (1) pre\u2010bind the convolution function, (2) drop the repeated `.astype(int)` calls inside `compute_ratio` by relying on boolean\u2192int promotion, and (3) speed up index finds in `propose_move` by using `np.flatnonzero` instead of `np.nonzero`. These changes reduce per\u2010iteration overhead without altering the overall logic:\n\n<<<<<<< SEARCH\nimport numpy as np\nfrom numpy.random import default_rng\n=======\nimport numpy as np\nfrom numpy.random import default_rng\n\n# Prebind convolution for performance\nconv = np.convolve\n>>>>>>> REPLACE\n\n---\n<<<<<<< SEARCH\n    # sumset via convolution\n    sums_conv = np.convolve(A_ind.astype(int), B_ind.astype(int))\n    num_sums = np.count_nonzero(sums_conv)\n    # diffset via convolution with reversed B\n    diffs_conv = np.convolve(A_ind.astype(int), B_ind[::-1].astype(int))\n    num_diffs = np.count_nonzero(diffs_conv)\n=======\n    # sumset via convolution (bool\u2192int promotion)\n    sums_conv = conv(A_ind, B_ind)\n    num_sums = np.count_nonzero(sums_conv)\n    # diffset via convolution with reversed B\n    diffs_conv = conv(A_ind, B_ind[::-1])\n    num_diffs = np.count_nonzero(diffs_conv)\n>>>>>>> REPLACE\n\n---\n<<<<<<< SEARCH\n    ones = np.nonzero(ind)[0]\n    zeros = np.nonzero(~ind)[0]\n=======\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n>>>>>>> REPLACE\n\nExplanation of benefits:\n- Prebinding `conv = np.convolve` saves a name lookup on each call.\n- Dropping the `.astype(int)` calls leverages NumPy\u2019s automatic promotion of boolean arrays to 0/1 in arithmetic, cutting out two array casts per convolution.\n- `np.flatnonzero` is a slightly faster path to the non\u2010zero indices than `np.nonzero(...)[0]`."]}}}