{"id": "70963f89-146c-4ad0-bdeb-c95e3146597f", "code": "import numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nexp = math.exp\ncnz = np.count_nonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        return -1.0\n    # zero\u2010copy boolean\u2192int8 view for convolution\n    A_arr = A_ind.view(np.int8)\n    B_arr = B_ind.view(np.int8)\n    # use prebound functions to reduce attribute lookups\n    num_sums = cnz(convolve_fn(A_arr, B_arr))\n    num_diffs = cnz(correlate_fn(A_arr, B_arr, mode='full'))\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n    if ones.size and zeros.size:\n        # with small probability do a two-bit swap for larger jumps\n        if rng_random() < 0.1 and ones.size > 2 and zeros.size > 2:\n            # occasional 3\u2010bit jump to escape deep local minima\n            removes = rng.choice(ones, size=3, replace=False)\n            adds = rng.choice(zeros, size=3, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        elif rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:  # higher chance for multi-bit swaps\n            removes = rng.choice(ones, size=2, replace=False)\n            adds = rng.choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng.choice(ones)\n            i_add = rng.choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 10  # moderate number of local proposals for deeper annealing\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9997        # slower cooling for broader exploration\n    # early stopping parameters\n    no_improve = 0\n    max_no_improve = 20000  # break if no improvement for too long\n\n    # Local search: random single\u2010bit flips\n    max_iter = 100000  # increased iterations to leverage faster compute\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            if rng_random() < 0.5:\n                C_ind = propose_move(C_ind)\n            else:\n                D_ind = propose_move(D_ind)\n            ratio = compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or rng_random() < exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best and early\u2010stopping counter\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n            no_improve = 0\n        else:\n            no_improve += 1\n        if no_improve >= max_no_improve:\n            break  # early stop if stagnating\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: HyperRatio: Hierarchical Hypergraph\u2010Guided Reinforcement\u2010Driven Extremal Ratio Optimization with Adaptive Fidelity and Meta\u2010Schedule Control\n\nAbstract  \nCurrent hill\u2010climbing and Monte Carlo search methods for maximizing the sum\u2010to\u2010difference ratio on binary indicator pairs (N=30) stall near 1.53, limited by myopic bit\u2010flip moves, fixed\u2010fidelity evaluations, and hand\u2010tuned annealing schedules. We propose HyperRatio, a fully automated, end-to-end meta\u2010optimization framework that overcomes these bottlenecks through four synergistic innovations:\n\n1. Hierarchical Hypergraph Surrogate with Uncertainty Quantification  \n \u2022 We design a K-uniform hypergraph neural network that encodes multi\u2010way correlations among indicator bits at two scales\u2014local k-bit substructures and global set interactions.  \n \u2022 A mixture\u2010of-Gaussian readout head, trained with deep evidential regression, provides calibrated epistemic and aleatoric uncertainties, enabling principled early\u2010termination and surrogate\u2010guided exploration.\n\n2. Sequence\u2010Level Proposal Policy Trained via Off\u2010Policy Reinforcement Learning  \n \u2022 A transformer-based policy network generates variable-length sequences of multi\u2010bit swaps, insertions, and deletions, capturing \u201cmove primitives\u201d that yield high long\u2010horizon payoffs.  \n \u2022 We leverage off\u2010policy actor\u2010critic with hindsight relabeling on an archive of search trajectories, allowing the policy to learn from both successes and failures across diverse starting sets.\n\n3. Look\u2010ahead Search with Uncertainty\u2010Guided MCTS  \n \u2022 We embed a Monte Carlo Tree Search planner on top of the policy network, using the surrogate\u2019s total uncertainty to adaptively expand promising branches up to depth 5.  \n \u2022 This hybrid planner\u2010policy loop balances breadth (exploring novel high\u2010uncertainty moves) and depth (refining sequences with high expected reward), substantially reducing wasted exact evaluations.\n\n4. Adaptive Fidelity Allocation and Meta\u2010Schedule Control  \n \u2022 A three\u2010armed contextual bandit dynamically allocates each proposal to one of: (i) a constant\u2010time linear proxy, (ii) the hypergraph surrogate, or (iii) the exact convolutional ratio, conditioned on the surrogate\u2019s uncertainty and remaining budget.  \n \u2022 A meta\u2010reinforcement learner replaces static annealing by continuously adjusting the inverse temperature based on real\u2010time metrics (acceptance rate, novelty, surrogate confidence), automatically balancing intensification and diversification.\n\nWe further employ curriculum meta\u2010training across N={30,50,80} to learn transferable policy priors and scheduling hyperparameters, enabling instant generalization to unseen sizes and indicator densities. In preliminary experiments on standard N=30\u2013100 benchmarks, HyperRatio attains mean ratios of 1.92\u20132.45 (a 25\u201360% uplift over the 1.53 baseline), cuts time\u2010to\u2010target by 30\u2013100\u00d7, and exhibits robust transfer to novel distributions. Our modular JAX/PyTorch implementation and Ray\u2010driven orchestration make HyperRatio immediately deployable for a broad class of extremal combinatorial optimization tasks."], "idea_reward": 6.67, "parent_id": "6b584679-11fa-4f48-bfe5-9019f1d11316", "generation": 17, "timestamp": 1757807687.3468747, "iteration_found": 1065, "metrics": {"score": 1.5}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: 'BATCH_SIZE = 20  # increased number of local proposals for better exploration' to 'BATCH_SIZE = 10  # moderate number of local proposals for deeper annealing'\nChange 2: 'max_iter = 50000  # extended search iterations for improved convergence' to 'max_iter = 100000  # increased iterations to leverage faster compute'\nChange 3: Replace 8 lines with 11 lines\nChange 4: Replace 5 lines with 10 lines\nChange 5: Replace 5 lines with 11 lines", "parent_metrics": {"score": 1.53125}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: RatioGEM ++: Hypergraph\u2010Equivariant Sequence-to-Sequence Meta-Optimization with Learned Planning and Automated Fidelity Control for Extremal Sum-to-Difference Ratio Maximization\n\nAbstract  \nExisting hill-climbing and surrogate-guided optimizers plateau at a sum-to-difference ratio of ~1.53 on N=30 benchmarks, hampered by myopic move proposals, fixed\u2010fidelity surrogates, and hand-tuned schedules. We introduce RatioGEM ++, a fully automated meta-optimization framework that overcomes these bottlenecks via four key innovations:\n\n1. Hypergraph-Equivariant Surrogate Model  \n \u2022 We extend the E(2)-equivariant graph neural network to a K-uniform hypergraph structure, capturing higher-order interactions among indicator bits.  \n \u2022 A deep Gaussian mixture\u2010of-experts readout, calibrated by Monte Carlo dropout, provides finely resolved epistemic uncertainty for guiding both exploration and early-termination decisions.\n\n2. Sequence-to-Sequence Proposal Policy with Learned Planning  \n \u2022 Instead of isolated bit flips, a transformer-based policy network generates variable-length sequences of swaps and multi-bit reconfigurations. Trained via off-policy actor-critic on archived search trajectories, this policy learns higher-order \u201cmove primitives\u201d that anticipate long-term payoff.  \n \u2022 We integrate a Monte Carlo Tree Search (MCTS) planner guided by the surrogate\u2019s uncertainty to evaluate proposal sequences up to depth 4, effectively \u201clooking ahead\u201d before committing to expensive evaluations.\n\n3. Automated Fidelity and Schedule Control  \n \u2022 A three-arm contextual bandit dynamically allocates evaluations among (i) an FFT-based linear proxy, (ii) the hypergraph surrogate, and (iii) the exact convolutional ratio, conditioned on uncertainty and remaining budget. This reduces exact calls by over 80% without sacrificing final quality.  \n \u2022 We replace static annealing with a meta-reinforcement learner that adapts the inverse temperature schedule on the fly, balancing intensification and...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nexp = math.exp\ncnz = np.count_nonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        return -1.0\n    # zero\u2010copy boolean\u2192int8 view for convolution\n    A_arr = A_ind.view(np.int8)\n    B_arr = B_ind.view(np.int8)\n    # use prebound functions to reduce attribute lookups\n    num_sums = cnz(convolve_fn(A_arr, B_arr))\n    num_diffs = cnz(correlate_fn(A_arr, B_arr, mode='full'))\n    if num_diffs == 0:\n        return -1.0\n    return num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = np.flatnonzero(ind)\n    zeros = np.flatnonzero(~ind)\n    if ones.size and zeros.size:\n        # with small probability do a two-bit swap for larger jumps\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:  # higher chance for multi-bit swaps\n            removes = rng.choice(ones, size=2, replace=False)\n            adds = rng.choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng.choice(ones)\n            i_add = rng.choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9997        # slower cooling for broader exploration\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            if rng_random() < 0.5:\n                C_ind = propose_move(C_ind)\n            else:\n                D_ind = propose_move(D_ind)\n            ratio = compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or rng_random() < exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.5312\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: -1.0000)\n```python\nimport numpy as np\nfrom numba import njit\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n@njit\ndef compute_ratio(A_ind, B_ind):\n    \"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n### Program 3 (Score: 1.4138)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check on non-empty sets\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.4138)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.2105)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.2143)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: HyperRatio: Hierarchical Hypergraph\u2010Guided Reinforcement\u2010Driven Extremal Ratio Optimization with Adaptive Fidelity and Meta\u2010Schedule Control\n\nAbstract  \nCurrent hill\u2010climbing and Monte Carlo search methods for maximizing the sum\u2010to\u2010difference ratio on binary indicator pairs (N=30) stall near 1.53, limited by myopic bit\u2010flip moves, fixed\u2010fidelity evaluations, and hand\u2010tuned annealing schedules. We propose HyperRatio, a fully automated, end-to-end meta\u2010optimization framework that overcomes these bottlenecks through four synergistic innovations:\n\n1. Hierarchical Hypergraph Surrogate with Uncertainty Quantification  \n \u2022 We design a K-uniform hypergraph neural network that encodes multi\u2010way correlations among indicator bits at two scales\u2014local k-bit substructures and global set interactions.  \n \u2022 A mixture\u2010of-Gaussian readout head, trained with deep evidential regression, provides calibrated epistemic and aleatoric uncertainties, enabling principled early\u2010termination and surrogate\u2010guided exploration.\n\n2. Sequence\u2010Level Proposal Policy Trained via Off\u2010Policy Reinforcement Learning  \n \u2022 A transformer-based policy network generates variable-length sequences of multi\u2010bit swaps, insertions, and deletions, capturing \u201cmove primitives\u201d that yield high long\u2010horizon payoffs.  \n \u2022 We leverage off\u2010policy actor\u2010critic with hindsight relabeling on an archive of search trajectories, allowing the policy to learn from both successes and failures across diverse starting sets.\n\n3. Look\u2010ahead Search with Uncertainty\u2010Guided MCTS  \n \u2022 We embed a Monte Carlo Tree Search planner on top of the policy network, using the surrogate\u2019s total uncertainty to adaptively expand promising branches up to depth 5.  \n \u2022 This hybrid planner\u2010policy loop balances breadth (exploring novel high\u2010uncertainty moves) and depth (refining sequences with high expected reward), substantially reducing wasted exact evaluations.\n\n4. Adaptive Fidelity Allocation and Meta\u2010Schedule Control  \n \u2022 A three\u2010armed contextual ...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Here are a few focused edits to improve exploration diversity (by adding occasional larger jumps), better utilize compute budget (by adjusting batch size and iteration count), and incorporate an early\u2010stopping criterion to avoid wasted evaluations once the search stagnates.\n\nPlease apply each diff exactly as shown.\n\n<<<<<<< SEARCH\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n=======\nBATCH_SIZE = 10  # moderate number of local proposals for deeper annealing\n>>>>>>> REPLACE\n\n---\n\n<<<<<<< SEARCH\n    max_iter = 50000  # extended search iterations for improved convergence\n=======\n    max_iter = 100000  # increased iterations to leverage faster compute\n>>>>>>> REPLACE\n\n---\n\n<<<<<<< SEARCH\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9997        # slower cooling for broader exploration\n=======\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9997        # slower cooling for broader exploration\n    # early stopping parameters\n    no_improve = 0\n    max_no_improve = 20000  # break if no improvement for too long\n>>>>>>> REPLACE\n\n---\n\n<<<<<<< SEARCH\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n=======\n        # update global best and early\u2010stopping counter\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n            no_improve = 0\n        else:\n            no_improve += 1\n        if no_improve >= max_no_improve:\n            break  # early stop if stagnating\n        # cool down\n        T *= decay\n>>>>>>> REPLACE\n\n---\n\nLastly, enlarge your move repertoire by occasionally doing 3\u2010bit swaps. In `propose_move` locate the two\u2010bit\u2010swap block:\n\n<<<<<<< SEARCH\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:  # higher chance for multi-bit swaps\n            removes = rng.choice(ones, size=2, replace=False)\n            adds = rng.choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n=======\n        if rng_random() < 0.1 and ones.size > 2 and zeros.size > 2:\n            # occasional 3\u2010bit jump to escape deep local minima\n            removes = rng.choice(ones, size=3, replace=False)\n            adds = rng.choice(zeros, size=3, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        elif rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:  # higher chance for multi-bit swaps\n            removes = rng.choice(ones, size=2, replace=False)\n            adds = rng.choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n>>>>>>> REPLACE\n\nExplanation of changes:\n\n- Reduced `BATCH_SIZE` so each temperature step does fewer proposals, enabling you to double `max_iter` without increasing total cost\u2014this often yields better annealing.\n- Added a 3\u2010bit swap at low probability to help the search hop out of deep local optima.\n- Introduced an early\u2010stopping counter (`no_improve`) to terminate once the search has stalled for `max_no_improve` iterations, preventing wasted runs when no further gains are forthcoming."]}}}