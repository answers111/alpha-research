{"id": "84c82d52-a081-440f-b0ff-1f22504b509c", "code": "import numpy as np\nfrom numpy.random import default_rng\n# Prebind numpy functions for performance\n_unique = np.unique\n_count_nonzero = np.count_nonzero\n_rint = np.rint\n_exp = np.exp\n\n# For reproducibility\nrng = default_rng(42)\n# simple cache for compute_ratio to avoid redundant computations\nratio_cache = {}\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # simple cache lookup to skip redundant computations\n    key = (A_ind.tobytes(), B_ind.tobytes())\n    if key in ratio_cache:\n        return ratio_cache[key]\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        # cache infeasible cases to avoid rechecking the same zero\u2010vector pair\n        ratio_cache[key] = -1.0\n        return -1.0\n    # sparse direct\u2010set approach for small supports, else FFT convolution\n    ones_A = np.flatnonzero(A_ind)\n    ones_B = np.flatnonzero(B_ind)\n    if ones_A.size * ones_B.size < 1000:\n        # Vectorized Minkowski sum/difference using numpy\n        sum_vals = ones_A[:, None] + ones_B[None, :]\n        dif_vals = ones_A[:, None] - ones_B[None, :]\n        num_sums = _unique(sum_vals).size\n        num_diffs = _unique(dif_vals).size\n        if num_diffs == 0:\n            ratio_cache[key] = -1.0\n            return -1.0\n        ratio = num_sums / num_diffs\n        ratio_cache[key] = ratio\n        return ratio\n    # FFT\u2010based convolution for larger supports (use real FFT for binary signals)\n    n = A_ind.size + B_ind.size - 1\n    fa = np.fft.rfft(A_ind.astype(float), n)\n    fb = np.fft.rfft(B_ind.astype(float), n)\n    sums_conv = _rint(np.fft.irfft(fa * fb, n)).astype(int)\n    num_sums = _count_nonzero(sums_conv)\n    # cross-correlation via conjugate multiplication\n    diffs_conv = _rint(np.fft.irfft(fa * np.conj(fb), n)).astype(int)\n    num_diffs = _count_nonzero(diffs_conv)\n    if num_diffs == 0:\n        ratio_cache[key] = -1.0\n        return -1.0\n    ratio = num_sums / num_diffs\n    ratio_cache[key] = ratio\n    return ratio\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Return a new vector with one bit added or removed, ensuring at least one '1'.\"\"\"\n    new_ind = ind.copy()\n    ones = np.flatnonzero(new_ind)\n    zeros = np.flatnonzero(~new_ind)\n    # if too few ones or by random choice, add\n    if zeros.size > 0 and (ones.size <= 1 or rng.random() < 0.5):\n        new_ind[rng.choice(zeros)] = True\n    # else remove (only if more than one one)\n    elif ones.size > 1:\n        new_ind[rng.choice(ones)] = False\n    return new_ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    # Evaluate initial ratio and initialize both current and best solutions\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    # simulated\u2010annealing schedule parameters\n    T0 = 1.0        # initial temperature\n    alpha = 0.999   # cooling rate\n    T = T0\n    for _ in range(max_iter):\n        # propose move on only one vector to reduce copying overhead\n        if rng.random() < 0.5:\n            # propose_move already copies internally, so pass current_A directly\n            C_ind = propose_move(current_A)\n            D_ind = current_B  # unchanged\n        else:\n            C_ind = current_A  # unchanged\n            # likewise avoid duplicate copy for B\n            D_ind = propose_move(current_B)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip invalid proposals immediately\n        if ratio < 0:\n            continue\n        # simulated\u2010annealing acceptance criterion\n        delta = ratio - current_ratio\n        if delta > 0 or rng.random() < np.exp(delta / T):\n            # accept as new current\n            current_A, current_B, current_ratio = C_ind.copy(), D_ind.copy(), ratio\n            # update global best if improved\n            if ratio > best_ratio:\n                # store the new best without extra copies\n                best_ratio, best_A, best_B = ratio, C_ind, D_ind\n        # cool down\n        T *= alpha\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: Meta-Learned Multi-Agent Hierarchical Search with Uncertainty-Aware Surrogates and Diversity-Driven Moves for High-Ratio Sum-to-Difference Optimization  \n\nAbstract:  \nCurrent single-agent hill-climbing and metaheuristic methods for maximizing the sum-to-difference ratio on large 0/1 indicator vectors stagnate due to greedy one-bit moves, poor memory of past states, and prohibitive full\u2010FFT evaluations. We propose a unified, implementable framework that builds on successful elements of GFlowNets, ensemble graph surrogates, and multi-fidelity bandits, while introducing novel mechanisms for diversity and meta-learning. Our key contributions are:\n\n1. Continuous Relaxation with Diversity-Seeking Move Generator  \n   \u2022 We learn a low-dimensional latent embedding of indicator vectors via a variational encoder. A Gumbel-Softmax policy network\u2014trained with a combined ratio-improvement and entropy-maximization loss\u2014proposes multi-bit transitions, enabling large jumps out of deep local optima while explicitly rewarding novel support patterns.\n\n2. Meta-Learnt Ensemble Surrogates with Dynamic Uncertainty Reweighting  \n   \u2022 An ensemble of lightweight bipartite Graph Neural Networks is meta-trained across small-N instances to predict ratio deltas and estimate epistemic uncertainty via Monte Carlo dropout. We dynamically reweight ensemble members based on online calibration errors, focusing full\u00ad-FFT calls only on the top 5% of high-uncertainty or high-potential proposals.\n\n3. Cooperative Multi-Agent Hierarchical Planning with Contextual Bandit Controller  \n   \u2022 Two specialized agents (\u201cMacro-Jump\u201d for broad reconfigurations and \u201cMicro-Tweak\u201d for local refinements) communicate through a shared replay buffer. A Thompson-sampling bandit controller allocates compute budget among agents, fidelity tiers, and move types, optimizing regret over time and adapting to observed search dynamics.\n\n4. Budget-Aware Adaptive Multi-Fidelity Evaluation  \n   \u2022 We organize evaluation into three graded fidelities: (i) AVX512-accelerated incremental convolution for micro-moves, (ii) subsampled FFT approximations for medium-scale proposals, (iii) full JAX/CUDA FFT only for final verification. A predictive scheduler enforces both per-iteration and global runtime budgets, targeting a \u226597% reduction in full FFT invocations.\n\nImplementation and Evaluation Plan:  \nWe will develop the core policy and surrogate models in PyTorch, continuous relaxations in JAX, and high-performance AVX512/C++ kernels for low-level convolutions. The contextual bandit and fidelity scheduler will be implemented in Python. We will benchmark on problems up to N=50,000 against hill-climbing, tabu search, genetic algorithms, and existing surrogate-assisted methods. We aim to surpass a ratio of 1.52 (current best 1.3846), reduce full FFT usage by \u226597%, and achieve per-iteration runtimes under 1\u2009ms. Success in this domain will readily extend to large-scale additive combinatorics, signal alignment, and related high-dimensional discrete optimization tasks."], "idea_reward": 6.67, "parent_id": "7aed7078-38e0-4cd5-9b0b-3ae85dd2707e", "generation": 15, "timestamp": 1757793502.6743503, "iteration_found": 785, "metrics": {"score": 1.3846153846153846}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 4 lines with 5 lines\nChange 2: Replace 3 lines with 3 lines\nChange 3: Replace 2 lines with 3 lines", "parent_metrics": {"score": 1.3846153846153846}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: Multi-Agent Surrogate-Guided Hierarchical Planning with Continuous Relaxation and Low-Fidelity Ensembles for Efficient Sum-to-Difference Ratio Maximization\n\nAbstract:  \nWe observe that current hill-climbing and single-agent metaheuristics for maximizing the sum-to-difference ratio on large indicator vectors suffer from (i) short-sighted, memoryless bit-flip moves that become trapped in deep local optima and (ii) excessive full-scale FFT evaluations, limiting scalability. Building on graph-based surrogates, multi-fidelity bandits, and hierarchical search, we propose an integrated framework with four key innovations:\n\n1. Continuous-Relaxation Move Generator with Gumbel-Softmax  \n   \u2022 We embed binary indicator vectors into a continuous latent space via a lightweight encoder and use Gumbel-Softmax parameterizations to propose multi\u2013bit flips in a single step.  \n   \u2022 A policy network (actor) trained with a diversity-seeking objective (GFlowNet loss) learns a probabilistic distribution over high-impact move patterns, significantly improving exploration of distant optima.\n\n2. Ensemble Graph-Neural-Network Surrogates with Uncertainty Quantification  \n   \u2022 Instead of a single transformer surrogate, we maintain an ensemble of shallow bipartite graph neural networks (GNNs) that predict ratio changes and provide Bayesian-style uncertainty estimates via Monte-Carlo dropout.  \n   \u2022 Uncertain or high-potential proposals trigger on-the-fly calibration using fast incremental convolution, reducing unnecessary full FFT calls by up to 95%.\n\n3. Hierarchical Multi-Agent Planning with Contextual Bandit Meta-Controller  \n   \u2022 We orchestrate two cooperating agents: a \u201cBlock-Merge\u201d planner for coarse, multi-bit jump proposals, and a \u201cLocal-Refine\u201d planner for fine bit flips, each guided by surrogate gradients and value estimates.  \n   \u2022 A contextual bandit controller dynamically allocates CPU/GPU resources and selects between agents, fidelity levels, and sampling strategies based on l...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n# Prebind numpy functions for performance\n_unique = np.unique\n_count_nonzero = np.count_nonzero\n_rint = np.rint\n\n# For reproducibility\nrng = default_rng(42)\n# simple cache for compute_ratio to avoid redundant computations\nratio_cache = {}\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # simple cache lookup to skip redundant computations\n    key = (A_ind.tobytes(), B_ind.tobytes())\n    if key in ratio_cache:\n        return ratio_cache[key]\n    # quick check\n    if not A_ind.any() or not B_ind.any():\n        # cache infeasible cases to avoid rechecking the same zero\u2010vector pair\n        ratio_cache[key] = -1.0\n        return -1.0\n    # sparse direct\u2010set approach for small supports, else FFT convolution\n    ones_A = np.flatnonzero(A_ind)\n    ones_B = np.flatnonzero(B_ind)\n    if ones_A.size * ones_B.size < 1000:\n        # Vectorized Minkowski sum/difference using numpy\n        sum_vals = ones_A[:, None] + ones_B[None, :]\n        dif_vals = ones_A[:, None] - ones_B[None, :]\n        num_sums = _unique(sum_vals).size\n        num_diffs = _unique(dif_vals).size\n        if num_diffs == 0:\n            ratio_cache[key] = -1.0\n            return -1.0\n        ratio = num_sums / num_diffs\n        ratio_cache[key] = ratio\n        return ratio\n    # FFT\u2010based convolution for larger supports (use real FFT for binary signals)\n    n = A_ind.size + B_ind.size - 1\n    fa = np.fft.rfft(A_ind.astype(float), n)\n    fb = np.fft.rfft(B_ind.astype(float), n)\n    sums_conv = _rint(np.fft.irfft(fa * fb, n)).astype(int)\n    num_sums = _count_nonzero(sums_conv)\n    # cross-correlation via conjugate multiplication\n    diffs_conv = _rint(np.fft.irfft(fa * np.conj(fb), n)).astype(int)\n    num_diffs = _count_nonzero(diffs_conv)\n    if num_diffs == 0:\n        ratio_cache[key] = -1.0\n        return -1.0\n    ratio = num_sums / num_diffs\n    ratio_cache[key] = ratio\n    return ratio\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Return a new vector with one bit added or removed, ensuring at least one '1'.\"\"\"\n    new_ind = ind.copy()\n    ones = np.flatnonzero(new_ind)\n    zeros = np.flatnonzero(~new_ind)\n    # if too few ones or by random choice, add\n    if zeros.size > 0 and (ones.size <= 1 or rng.random() < 0.5):\n        new_ind[rng.choice(zeros)] = True\n    # else remove (only if more than one one)\n    elif ones.size > 1:\n        new_ind[rng.choice(ones)] = False\n    return new_ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = True\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    # Evaluate initial ratio and initialize both current and best solutions\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    # simulated\u2010annealing schedule parameters\n    T0 = 1.0        # initial temperature\n    alpha = 0.999   # cooling rate\n    T = T0\n    for _ in range(max_iter):\n        # propose move on only one vector to reduce copying overhead\n        if rng.random() < 0.5:\n            # propose_move already copies internally, so pass current_A directly\n            C_ind = propose_move(current_A)\n            D_ind = current_B  # unchanged\n        else:\n            C_ind = current_A  # unchanged\n            # likewise avoid duplicate copy for B\n            D_ind = propose_move(current_B)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip invalid proposals immediately\n        if ratio < 0:\n            continue\n        # simulated\u2010annealing acceptance criterion\n        delta = ratio - current_ratio\n        if delta > 0 or rng.random() < np.exp(delta / T):\n            # accept as new current\n            current_A, current_B, current_ratio = C_ind.copy(), D_ind.copy(), ratio\n            # update global best if improved\n            if ratio > best_ratio:\n                best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n        # cool down\n        T *= alpha\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.3846\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5312\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5455)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5455)\n\n\n### Program 2 (Score: 0.9714)\n```python\nimport numpy as np\nfrom numba import njit\n# use numba JIT for compute_ratio to accelerate loops\nfrom numpy import exp   # use NumPy's exp for consistent C\u2010speed calls\nfrom numpy.random import default_rng\n# Prebind convolution for faster inner\u2010loop calls\nconvolve = np.convolve\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (0.9714)\n\n\n### Program 3 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    \"\"\"\n    Compute the sum-to-difference ratio R(A,B) = |A+B| / |A-B|.\n    Return -1 if denominator is zero (invalid).\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -1.0000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Cache for computed ratios to avoid redundant convolution calls\n# ... (truncated)\n```\nKey features: Alternative approach to error\n\n\n### Program D2 (Score: 1.4516)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: Meta-Learned Multi-Agent Hierarchical Search with Uncertainty-Aware Surrogates and Diversity-Driven Moves for High-Ratio Sum-to-Difference Optimization  \n\nAbstract:  \nCurrent single-agent hill-climbing and metaheuristic methods for maximizing the sum-to-difference ratio on large 0/1 indicator vectors stagnate due to greedy one-bit moves, poor memory of past states, and prohibitive full\u2010FFT evaluations. We propose a unified, implementable framework that builds on successful elements of GFlowNets, ensemble graph surrogates, and multi-fidelity bandits, while introducing novel mechanisms for diversity and meta-learning. Our key contributions are:\n\n1. Continuous Relaxation with Diversity-Seeking Move Generator  \n   \u2022 We learn a low-dimensional latent embedding of indicator vectors via a variational encoder. A Gumbel-Softmax policy network\u2014trained with a combined ratio-improvement and entropy-maximization loss\u2014proposes multi-bit transitions, enabling large jumps out of deep local optima while explicitly rewarding novel support patterns.\n\n2. Meta-Learnt Ensemble Surrogates with Dynamic Uncertainty Reweighting  \n   \u2022 An ensemble of lightweight bipartite Graph Neural Networks is meta-trained across small-N instances to predict ratio deltas and estimate epistemic uncertainty via Monte Carlo dropout. We dynamically reweight ensemble members based on online calibration errors, focusing full\u00ad-FFT calls only on the top 5% of high-uncertainty or high-potential proposals.\n\n3. Cooperative Multi-Agent Hierarchical Planning with Contextual Bandit Controller  \n   \u2022 Two specialized agents (\u201cMacro-Jump\u201d for broad reconfigurations and \u201cMicro-Tweak\u201d for local refinements) communicate through a shared replay buffer. A Thompson-sampling bandit controller allocates compute budget among agents, fidelity tiers, and move types, optimizing regret over time and adapting to observed search dynamics.\n\n4. Budget-Aware Adaptive Multi-Fidelity Evaluation  \n   \u2022 We organize evaluation into three ...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Here are a few targeted changes that will reduce Python\u2010level overhead (fewer array copies and attribute lookups) and should improve throughput without altering the core algorithm:\n\n<<<<<<< SEARCH\n# Prebind numpy functions for performance\n_unique = np.unique\n_count_nonzero = np.count_nonzero\n_rint = np.rint\n=======\n# Prebind numpy functions for performance\n_unique = np.unique\n_count_nonzero = np.count_nonzero\n_rint = np.rint\n_exp = np.exp\n>>>>>>> REPLACE\n\nReasoning: adding a local `_exp` binding avoids the global lookup of `np.exp` in the hot inner loop.\n\n---\n\n<<<<<<< SEARCH\n            if delta > 0 or rng.random() < np.exp(delta / T):\n                # accept as new current\n                current_A, current_B, current_ratio = C_ind.copy(), D_ind.copy(), ratio\n=======\n            if delta > 0 or rng.random() < _exp(delta / T):\n                # accept as new current (no need to copy; C_ind/D_ind are fresh or safe to reuse)\n                current_A, current_B, current_ratio = C_ind, D_ind, ratio\n>>>>>>> REPLACE\n\nReasoning: replace `np.exp` with `_exp` and eliminate the redundant `.copy()` calls when assigning the new \u201ccurrent\u201d solution. `C_ind` is already a private array from `propose_move` and `D_ind` still points to the unchanged older array, so we can reuse both directly.\n\n---\n\n<<<<<<< SEARCH\n            if ratio > best_ratio:\n                best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n=======\n            if ratio > best_ratio:\n                # store the new best without extra copies\n                best_ratio, best_A, best_B = ratio, C_ind, D_ind\n>>>>>>> REPLACE\n\nReasoning: similarly, when updating the global best we can store the references directly (they won\u2019t be mutated), avoiding two more potentially expensive array copies.\n\nThese three small changes cut down on Python\u2010level bookkeeping and should yield a noticeable speedup in the inner\u2010loop of your hill\u2010climbing search."]}}}