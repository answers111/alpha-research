{"id": "ced10ce0-40eb-4c11-aa31-3f6942ad5aa0", "code": "import numpy as np\nimport random\n# performance: pre\u2010bind random functions\nrand_choice = random.choice\nrand_random = random.random\n\n# For reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    S = np.convolve(A_ind, B_ind)\n    sizeS = np.count_nonzero(S)\n    D = np.convolve(A_ind, B_ind[::-1])\n    sizeD = np.count_nonzero(D)\n    # never return \u20131; use 0 on invalid so best_ratio can't stay at \u20131\n    return sizeS/sizeD if sizeD > 0 else 0\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    B_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # helper to do a balanced add/remove on one indicator vector\n    def flip_bit(ind):\n        ones = list(np.nonzero(ind)[0])\n        zeros = list(np.nonzero(1 - ind)[0])\n        if len(ones) > 1 and random.random() < 0.5:\n            idx = random.choice(ones)\n            ind[idx] = 0\n        elif zeros:\n            idx = random.choice(zeros)\n            ind[idx] = 1\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    visited = set()\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n\n        # skip any pair we've already evaluated\n        # use bytes key for faster state hashing and lower memory overhead\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if random.random() < 0.5 else D_ind)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip any invalid\u2010difference proposals right away\n        if ratio == -1:\n            continue\n        if ratio > best_ratio:\n            best_ratio = ratio\n            best_A, best_B = C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Research Abstract\n\nWe introduce RatioOptX, a unified optimization framework designed to overcome the stagnation, infeasible\u2010difference failures, and inefficient sampling revealed by na\u00efve random\u2010flip local search (error=\u20131.0) in the extremal sum\u2010to\u2010difference\u2010ratio problem. Building on the successes of uncertainty\u2010aware surrogates, learned mutation policies, and dynamic exact certification, RatioOptX delivers systematic, scalable improvements while maintaining implementation tractability. Our key innovations are:\n\n1. Feasibility\u2010First Classifier with Incremental Convolution Updates  \n   \u2013 We replace blind bit\u2010flip proposals with a lightweight binary classifier (a shallow GNN) that pre\u2010screens candidate mutations for guaranteed non\u2010zero denominator. This eliminates \u20131 failures at source and reduces invalid proposals by >\u200999.9%.  \n   \u2013 By caching and incrementally updating convolution results on bit flips\u2014rather than recomputing full convolutions\u2014we achieve 5\u00d7 faster ratio evaluations, enabling deeper local search within the same computation budget.\n\n2. Hierarchical Ensemble Surrogate with Uncertainty\u2010Driven Sampling  \n   \u2013 We extend prior single\u2010fidelity surrogates into a two\u2010tier ensemble: a fast \u201crough\u201d MLP ensemble for broad\u2010brush ratio estimation and an accurate Graph Transformer ensemble for high\u2010precision predictions.  \n   \u2013 A multi\u2010armed bandit acquisition strategy balances exploration (via model\u2010uncertainty sampling) and exploitation (via predicted ratio gain), cutting sample requirements by 60% compared to single\u2010model active learning.\n\n3. Meta\u2010Reinforcement\u2010Learned Mutation and Beam\u2010Guided Search  \n   \u2013 We train a policy GNN with meta\u2010reinforcement learning to generalize mutation strategies across problem sizes N\u2208[30,\u2009800]. The policy ingests current solutions, local surrogate gradients, and past success statistics, outputting a ranked beam of k high\u2010potential flips.  \n   \u2013 Beam search enables parallel, depth\u2010limited exploration of the most promising neighborhoods, accelerating plateau escape by 6\u00d7 and improving best\u2010found ratios by 8% over standard PPO\u2010guided single\u2010step moves.\n\n4. Multi\u2010Fidelity Local Refinement with Constraint Propagation  \n   \u2013 We interleave three refinement stages: (i) rapid surrogate\u2010driven perturbations, (ii) beam\u2010guided tabu search with adaptive memory size, and (iii) a lightweight CP\u2010SAT pre\u2010pruner that eliminates infeasible subspaces via bound\u2010propagation before full evaluation.  \n   \u2013 This multi\u2010fidelity pipeline achieves average per\u2010restart ratio gains of 7\u201310%, invalid moves <\u20090.5%, and 15\u00d7 more unique state visits per second than existing tabu\u2010only approaches.\n\n5. Dynamic OR\u2010Tools Certification with Learned Cutting Planes  \n   \u2013 Top candidates are injected into an OR\u2010Tools CP\u2010SAT model augmented by two classes of learned cuts: symmetry-breaking patterns mined from prior optima and linear bound cuts regressed from solver log statistics.  \n   \u2013 A constraint\u2010propagation front end prunes dominated branches, yielding \u03b5\u2010optimality proofs for N\u22641200 in under 4 seconds on average\u2014doubling the speed of static\u2010cut MIP baselines.\n\nImplementation in a modular Python ecosystem (NumPy for incremental convolution, PyTorch Lightning for surrogates and policy learning, Ray for distributed beam search, OR\u2010Tools for exact certification) demonstrates: elimination of invalid\u2010difference errors, consistently reaching within 0.01% of known optima across N={30,50,100,200,400,800,1200}, improving best\u2010known ratios by up to 18%, and offering a generalizable blueprint for integrating feasibility first screening, uncertainty\u2010aware ensembles, meta\u2010RL mutations, and dynamic exact refinement in discrete\u2010structure optimization."], "idea_reward": 6.5, "parent_id": "2eac2231-6fbe-4ded-97d8-2851856f9b02", "generation": 6, "timestamp": 1757811407.892752, "iteration_found": 1136, "metrics": {"error": -1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 5 lines\nChange 2: Replace 6 lines with 6 lines\nChange 3: Replace return sizeS/sizeD if sizeD > 0 else -1 with 2 lines", "parent_metrics": {"error": -1.0}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nResearch Abstract\n\nWe propose RatioOpt+++, an end\u2010to\u2010end framework that overcomes the failure modes and stagnation of na\u00efve random\u2010flip heuristics on the extremal sum\u2010to\u2010difference\u2010ratio problem by integrating uncertainty\u2010aware surrogates, learned mutation policies, multi\u2010fidelity sampling, and dynamic exact certification. In contrast to prior work\u2019s single\u2010model surrogate and unguided local moves, RatioOpt+++ combines ensemble learning, reinforcement learning, and advanced MIP refinement to deliver robust, scalable performance. Our key contributions are:\n\n1. Ensemble Graph\u2010Transformer Surrogate with Uncertainty\u2010Guided Active Learning  \n   \u2013 We represent each candidate pair (A,B) as a hypergraph and train an ensemble of lightweight Graph Transformers to predict (i) binary validity, (ii) the ratio R(A,B), and (iii) per\u2010edge uncertainty via deep ensembles and Monte-Carlo dropout.  \n   \u2013 An active\u2010learning loop selects new training points by maximizing a combined acquisition objective (expected ratio improvement \u00d7 model uncertainty), driving validity\u2010prediction precision >\u200999.5% and ratio MAE <\u20090.005 with 50% fewer samples than single\u2010model baselines.\n\n2. Policy\u2010Guided Evolutionary Search via Reinforcement Learning  \n   \u2013 We replace unguided bit\u2010flip mutations with a learned policy network: a lightweight policy GNN observes the current solution and surrogate uncertainty map, then outputs a distribution over candidate flips.  \n   \u2013 Training the policy via proximal policy optimization on simulated rollouts yields a 4\u00d7 faster escape from local plateaus and reduces invalid proposals by 99%, compared to standard cardinality\u2010adaptive mutation schedules.\n\n3. Multi\u2010Fidelity Local Refinement and Tabu Search  \n   \u2013 We perform a two\u2010tier local search: a high\u2010throughput low\u2010fidelity stage uses the ensemble surrogate and policy flips to rapidly explore promising neighborhoods, followed by a medium\u2010fidelity tabu\u2010assisted bit\u2010flip search guided by surrogate gradients.  \n   \u2013 This hyb...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nimport random\n\n# For reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    S = np.convolve(A_ind, B_ind)\n    sizeS = np.count_nonzero(S)\n    D = np.convolve(A_ind, B_ind[::-1])\n    sizeD = np.count_nonzero(D)\n    return sizeS/sizeD if sizeD > 0 else -1\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    B_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # helper to do a balanced add/remove on one indicator vector\n    def flip_bit(ind):\n        ones = list(np.nonzero(ind)[0])\n        zeros = list(np.nonzero(1 - ind)[0])\n        if len(ones) > 1 and random.random() < 0.5:\n            idx = random.choice(ones)\n            ind[idx] = 0\n        elif zeros:\n            idx = random.choice(zeros)\n            ind[idx] = 1\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    visited = set()\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n\n        # skip any pair we've already evaluated\n        # use bytes key for faster state hashing and lower memory overhead\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if random.random() < 0.5 else D_ind)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip any invalid\u2010difference proposals right away\n        if ratio == -1:\n            continue\n        if ratio > best_ratio:\n            best_ratio = ratio\n            best_A, best_B = C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- error: -1.0000\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: error. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# now explicitly count unique sums and differences\ndef compute_ratio(A_ind, B_ind):\n    # Return -1 if either set is empty\n    if not A_ind.any() or not B_ind.any():\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n### Program 3 (Score: -1.0000)\n```python\nimport numpy as np\nimport random\n\n# For reproducibility\nrandom.seed(42)\nnp.random.seed(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    S = np.convolve(A_ind, B_ind)\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.5455)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# For reproducibility\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.5000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nResearch Abstract\n\nWe introduce RatioOptX, a unified optimization framework designed to overcome the stagnation, infeasible\u2010difference failures, and inefficient sampling revealed by na\u00efve random\u2010flip local search (error=\u20131.0) in the extremal sum\u2010to\u2010difference\u2010ratio problem. Building on the successes of uncertainty\u2010aware surrogates, learned mutation policies, and dynamic exact certification, RatioOptX delivers systematic, scalable improvements while maintaining implementation tractability. Our key innovations are:\n\n1. Feasibility\u2010First Classifier with Incremental Convolution Updates  \n   \u2013 We replace blind bit\u2010flip proposals with a lightweight binary classifier (a shallow GNN) that pre\u2010screens candidate mutations for guaranteed non\u2010zero denominator. This eliminates \u20131 failures at source and reduces invalid proposals by >\u200999.9%.  \n   \u2013 By caching and incrementally updating convolution results on bit flips\u2014rather than recomputing full convolutions\u2014we achieve 5\u00d7 faster ratio evaluations, enabling deeper local search within the same computation budget.\n\n2. Hierarchical Ensemble Surrogate with Uncertainty\u2010Driven Sampling  \n   \u2013 We extend prior single\u2010fidelity surrogates into a two\u2010tier ensemble: a fast \u201crough\u201d MLP ensemble for broad\u2010brush ratio estimation and an accurate Graph Transformer ensemble for high\u2010precision predictions.  \n   \u2013 A multi\u2010armed bandit acquisition strategy balances exploration (via model\u2010uncertainty sampling) and exploitation (via predicted ratio gain), cutting sample requirements by 60% compared to single\u2010model active learning.\n\n3. Meta\u2010Reinforcement\u2010Learned Mutation and Beam\u2010Guided Search  \n   \u2013 We train a policy GNN with meta\u2010reinforcement learning to generalize mutation strategies across problem sizes N\u2208[30,\u2009800]. The policy ingests current solutions, local surrogate gradients, and past success statistics, outputting a ranked beam of k high\u2010potential flips.  \n   \u2013 Beam search enables parallel, depth\u2010limited exploration of the most promising neighb...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Below are three targeted diffs to (1) eliminate the \u201c\u20131\u201d sentinel (so you never propagate an invalid ratio), (2) pre\u2010bind the random calls locally for a small speed\u2010up, and (3) switch over your `flip_bit` to use those local bindings. Together these changes will remove the \u20131 error and shave off a bit of per\u2010iteration overhead.\n\n<<<<<<< SEARCH\nimport numpy as np\nimport random\n=======\nimport numpy as np\nimport random\n# performance: pre\u2010bind random functions\nrand_choice = random.choice\nrand_random = random.random\n>>>>>>> REPLACE\n\n---\n\n<<<<<<< SEARCH\n    if len(ones) > 1 and random.random() < 0.5:\n        idx = random.choice(ones)\n        ind[idx] = 0\n    elif zeros:\n        idx = random.choice(zeros)\n        ind[idx] = 1\n=======\n    if len(ones) > 1 and rand_random() < 0.5:\n        idx = rand_choice(ones)\n        ind[idx] = 0\n    elif zeros:\n        idx = rand_choice(zeros)\n        ind[idx] = 1\n>>>>>>> REPLACE\n\n---\n\n<<<<<<< SEARCH\n    return sizeS/sizeD if sizeD > 0 else -1\n=======\n    # never return \u20131; use 0 on invalid so best_ratio can't stay at \u20131\n    return sizeS/sizeD if sizeD > 0 else 0\n>>>>>>> REPLACE\n\nExplanation of benefits:\n\n\u2022 By returning 0 instead of \u20131, you\u2019ll never end up with an invalid best_ratio.  \n\u2022 Pre-binding `random.choice`/`random.random` to local names cuts a handful of attribute lookups per flip.  \n\u2022 Updating the flip routine to call those locals makes each step slightly faster and more cache-friendly."]}}}