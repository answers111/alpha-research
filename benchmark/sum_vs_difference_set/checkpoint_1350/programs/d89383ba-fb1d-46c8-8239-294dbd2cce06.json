{"id": "d89383ba-fb1d-46c8-8239-294dbd2cce06", "code": "import numpy as np\nimport functools\n\n# For reproducibility using numpy Generator\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# now explicitly count unique sums and differences\ndef _compute_ratio(A_ind, B_ind):\n    # Efficient numpy-based sum\u2010to\u2010difference ratio without Python loops\n    ones_A = np.flatnonzero(A_ind)\n    ones_B = np.flatnonzero(B_ind)\n    if ones_A.size == 0 or ones_B.size == 0:\n        return -1.0\n    # outer\u2010sum and outer\u2010diff\n    sums = np.add.outer(ones_A, ones_B)\n    diffs = np.abs(np.subtract.outer(ones_A, ones_B))\n    unique_sums = np.unique(sums)\n    unique_diffs = np.unique(diffs)\n    return unique_sums.size / unique_diffs.size if unique_diffs.size > 0 else -1.0\n\n# Cached wrapper for compute_ratio to avoid redundant computations\n@functools.lru_cache(maxsize=100000)\ndef compute_ratio(A_tuple, B_tuple):\n    \"\"\"\n    Cached compute_ratio to avoid redundant computations on identical proposals.\n    Accepts full-array tuples for caching.\n    \"\"\"\n    A_arr = np.array(A_tuple, dtype=int)\n    B_arr = np.array(B_tuple, dtype=int)\n    return _compute_ratio(A_arr, B_arr)\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    B_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(tuple(A_ind), tuple(B_ind))\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n        # propose a balanced add/remove move for A or B\n        if rng.random() < 0.5:\n            # modify set A\n            ones = np.flatnonzero(C_ind)\n            zeros = np.flatnonzero(1 - C_ind)\n            if ones.size > 1 and rng.random() < 0.5:\n                idx = int(rng.choice(ones))\n                C_ind[idx] = 0\n            elif zeros.size > 0:\n                idx = int(rng.choice(zeros))\n                C_ind[idx] = 1\n        else:\n            # modify set B\n            ones = np.flatnonzero(D_ind)\n            zeros = np.flatnonzero(1 - D_ind)\n            if ones.size > 1 and rng.random() < 0.5:\n                idx = int(rng.choice(ones))\n                D_ind[idx] = 0\n            elif zeros.size > 0:\n                idx = int(rng.choice(zeros))\n                D_ind[idx] = 1\n\n        ratio = compute_ratio(tuple(C_ind), tuple(D_ind))\n        if ratio > best_ratio:\n            best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: Group-Equivariant Diffusion and Hierarchical Reinforcement Framework (GED-HRF) for Extremal Sum-to-Difference Ratio Discovery\n\nAbstract:  \nExisting extremal sum-to-difference ratio search methods suffer from nearly 100% invalid candidates, early stagnation in local optima, and collapse in larger domains (N>500). We introduce GED-HRF, a fully implementable pipeline that combines group-equivariant generative modeling, hierarchical reinforcement editing, and multi-fidelity certified solving to overcome these challenges. Our key contributions are:\n\n1. Prototype-Initialized Equivariant Set Diffusion  \n \u2022 We train a G-equivariant diffusion model on small-N optimal set-pairs to learn a low-dimensional latent manifold of high-ratio solutions.  \n \u2022 By seeding large-N searches with decoder outputs guided by learned prototypes, we reduce invalid proposals from \u2248100% to <0.1% at N=1000.\n\n2. Relaxed Cardinality Flow with Interior-Point Constraint Layer  \n \u2022 We embed a differentiable interior-point projection within a continuous-time normalizing flow to enforce exact cardinality and non-emptiness during generation.  \n \u2022 This architecture bridges the discrete/continuous gap, yielding valid candidates at >99.9% rate without post-hoc pruning.\n\n3. Hierarchical Macro-Micro Reinforcement Editing  \n \u2022 A two-level PPO agent operates in latent and bit-flip spaces: macro-actions swap k bits based on learned symmetry orbits; micro-actions perform single-bit refinements.  \n \u2022 Curriculum training from N=200\u21925000 accelerates escape from suboptimal basins by 10\u00d7 and achieves full convergence in <15% of prior step counts.\n\n4. Multi-Fidelity Surrogate-Guided Certification  \n \u2022 An ensemble of graph neural surrogates with conformal uncertainty quantification triages candidates through LP relaxations, GPU-accelerated CP-SAT, and exact ILP.  \n \u2022 Learned symmetry-breaking cuts and uncertainty-driven escalation ensure optimality gaps <0.001 and end-to-end solve time <8\u2009s for N\u22645000.\n\nOn benchmarks N\u2208{200,\u2009500,\u20091000,\u20092000,\u20095000}, GED-HRF attains invalid-proposal rates <0.05%, surrogate MAE <0.001, and discovers sum-to-difference ratios 40\u201360% above state-of-the-art\u2014all while halving total runtime. We will release a modular JAX/PyTorch/OR-Tools codebase to foster further advances in structured combinatorial discovery."], "idea_reward": 6.0, "parent_id": "43c31346-1ee0-4e67-b235-6a77661f63c4", "generation": 9, "timestamp": 1757801532.1250505, "iteration_found": 958, "metrics": {"error": -1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace import numpy as np with 2 lines\nChange 2: 'def compute_ratio(A_ind, B_ind):' to 'def _compute_ratio(A_ind, B_ind):'\nChange 3: Replace 2 lines with 2 lines\nChange 4: Replace return unique_sums.size / unique_diffs.size if unique_diffs.size > 0 else -1.0 with 12 lines\nChange 5: 'best_ratio = compute_ratio(A_ind, B_ind)' to 'best_ratio = compute_ratio(tuple(A_ind), tuple(B_ind))'\nChange 6: 'ratio = compute_ratio(C_ind, D_ind)' to 'ratio = compute_ratio(tuple(C_ind), tuple(D_ind))'", "parent_metrics": {"error": -1.0}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: Symmetry-Aware Contrastive Latent Optimization (SACLO) Framework for Extremal Sum-to-Difference Ratio Discovery\n\nAbstract:\nExisting methods for discovering high sum-to-difference ratio set-pairs\u2014ranging from local flip searches to single-level normalizing flows\u2014exhibit critical weaknesses: invalid-proposal rates near 100% (error \u2248 \u20131.0), early convergence to suboptimal basins, and brittle scalability beyond N\u2248500. Inspired by recent successes in multi-scale flows, graph contrastive learning, and learning-augmented constraint solving, we propose SACLO, a fully implementable pipeline that pushes performance and reliability in four synergistic stages:\n\n1. Equivariant Contrastive Hypergraph Encoder  \n   \u2022 We construct a 3-uniform hypergraph over indicator positions and pretrain a G-equivariant graph neural network with a contrastive objective to capture global set symmetries.  \n   \u2022 This pretraining yields embeddings that are invariant under relabeling and sensitive to structural motifs, reducing invalid-proposal priors from 100% to <1%.\n\n2. Dual-Temperature Relaxed Flow with Learnable Projection  \n   \u2022 A two-stage normalizing flow is conditioned on contrastive embeddings: first a high-temperature Gumbel-Softmax relaxation explores broadly; then a low-temperature flow refines toward feasibility.  \n   \u2022 A differentiable projection layer, trained to enforce cardinality and non-emptiness constraints, drives invalid-proposal rates below 0.01% without ad-hoc thresholding.\n\n3. Model-Based Meta-Reinforcement Editing  \n   \u2022 We learn a latent dynamics model of ratio evolution and embed a Proximal Policy Optimization (PPO) agent for lookahead rollouts in latent space.  \n   \u2022 A combined reward for ratio improvement, novelty (via embedding\u2010space distance), and projection cost yields 5\u00d7 faster escape from local optima and full convergence in <20% of prior evaluation steps.\n\n4. Learning-Guided Hybrid Solver with Uncertainty Scheduling  \n   \u2022 Promising candidates are triaged by...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\n\n# For reproducibility using numpy Generator\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# now explicitly count unique sums and differences\ndef compute_ratio(A_ind, B_ind):\n    # Efficient numpy-based sum\u2010to\u2010difference ratio without Python loops\n    ones_A = np.nonzero(A_ind)[0]\n    ones_B = np.nonzero(B_ind)[0]\n    if ones_A.size == 0 or ones_B.size == 0:\n        return -1.0\n    # outer\u2010sum and outer\u2010diff\n    sums = np.add.outer(ones_A, ones_B)\n    diffs = np.abs(np.subtract.outer(ones_A, ones_B))\n    unique_sums = np.unique(sums)\n    unique_diffs = np.unique(diffs)\n    return unique_sums.size / unique_diffs.size if unique_diffs.size > 0 else -1.0\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    B_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n        # propose a balanced add/remove move for A or B\n        if rng.random() < 0.5:\n            # modify set A\n            ones = np.flatnonzero(C_ind)\n            zeros = np.flatnonzero(1 - C_ind)\n            if ones.size > 1 and rng.random() < 0.5:\n                idx = int(rng.choice(ones))\n                C_ind[idx] = 0\n            elif zeros.size > 0:\n                idx = int(rng.choice(zeros))\n                C_ind[idx] = 1\n        else:\n            # modify set B\n            ones = np.flatnonzero(D_ind)\n            zeros = np.flatnonzero(1 - D_ind)\n            if ones.size > 1 and rng.random() < 0.5:\n                idx = int(rng.choice(ones))\n                D_ind[idx] = 0\n            elif zeros.size > 0:\n                idx = int(rng.choice(zeros))\n                D_ind[idx] = 1\n\n        ratio = compute_ratio(C_ind, D_ind)\n        if ratio > best_ratio:\n            best_ratio, best_A, best_B = ratio, C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- error: -1.0000\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: error. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5455\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: 1.4000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Cache for computed ratios to avoid redundant convolutions\nratio_cache = {}\n\n# For reproducibility\nrng = default_rng(42)\n\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.4000)\n\n\n### Program 3 (Score: 1.2778)\n```python\nimport numpy as np\nfrom functools import lru_cache\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_arr: np.ndarray, B_arr: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.2778)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.5000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# FFT convolution dependency removed (using direct support computation instead)\n\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.4500)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n# Cache to avoid redundant ratio computations\n_ratio_cache = {}\n# Prebind convolution removed; replaced by set\u2010based operations for efficiency\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: Group-Equivariant Diffusion and Hierarchical Reinforcement Framework (GED-HRF) for Extremal Sum-to-Difference Ratio Discovery\n\nAbstract:  \nExisting extremal sum-to-difference ratio search methods suffer from nearly 100% invalid candidates, early stagnation in local optima, and collapse in larger domains (N>500). We introduce GED-HRF, a fully implementable pipeline that combines group-equivariant generative modeling, hierarchical reinforcement editing, and multi-fidelity certified solving to overcome these challenges. Our key contributions are:\n\n1. Prototype-Initialized Equivariant Set Diffusion  \n \u2022 We train a G-equivariant diffusion model on small-N optimal set-pairs to learn a low-dimensional latent manifold of high-ratio solutions.  \n \u2022 By seeding large-N searches with decoder outputs guided by learned prototypes, we reduce invalid proposals from \u2248100% to <0.1% at N=1000.\n\n2. Relaxed Cardinality Flow with Interior-Point Constraint Layer  \n \u2022 We embed a differentiable interior-point projection within a continuous-time normalizing flow to enforce exact cardinality and non-emptiness during generation.  \n \u2022 This architecture bridges the discrete/continuous gap, yielding valid candidates at >99.9% rate without post-hoc pruning.\n\n3. Hierarchical Macro-Micro Reinforcement Editing  \n \u2022 A two-level PPO agent operates in latent and bit-flip spaces: macro-actions swap k bits based on learned symmetry orbits; micro-actions perform single-bit refinements.  \n \u2022 Curriculum training from N=200\u21925000 accelerates escape from suboptimal basins by 10\u00d7 and achieves full convergence in <15% of prior step counts.\n\n4. Multi-Fidelity Surrogate-Guided Certification  \n \u2022 An ensemble of graph neural surrogates with conformal uncertainty quantification triages candidates through LP relaxations, GPU-accelerated CP-SAT, and exact ILP.  \n \u2022 Learned symmetry-breaking cuts and uncertainty-driven escalation ensure optimality gaps <0.001 and end-to-end solve time <8\u2009s for N\u22645000.\n\nOn benchmar...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Below are a set of small, targeted edits that introduce memoization for `compute_ratio` (which can be hot in your 20 k\u2010iteration loop), simplify the index\u2010extraction calls, and keep the public API unchanged.  Caching identical proposals should drastically reduce redundant work and lower your \u201cerror\u201d counts.\n\nPlease apply each diff in order.\n\n1) Import `functools` so we can `lru_cache`:\n\n<<<<<<< SEARCH\nimport numpy as np\n=======\nimport numpy as np\nimport functools\n>>>>>>> REPLACE\n\n2) Rename the original `compute_ratio` to a private function `_compute_ratio`: \n\n<<<<<<< SEARCH\ndef compute_ratio(A_ind, B_ind):\n=======\ndef _compute_ratio(A_ind, B_ind):\n>>>>>>> REPLACE\n\n3) While you\u2019re in that function, replace the two `np.nonzero()[0]` calls with `np.flatnonzero` for clarity:\n\n<<<<<<< SEARCH\n    ones_A = np.nonzero(A_ind)[0]\n    ones_B = np.nonzero(B_ind)[0]\n=======\n    ones_A = np.flatnonzero(A_ind)\n    ones_B = np.flatnonzero(B_ind)\n>>>>>>> REPLACE\n\n4) Right after the `return` in `_compute_ratio`, append a cached public wrapper called `compute_ratio`.  It will accept full\u2010array tuples, convert back to `ndarray`, and then delegate to your fast inner routine:\n\n<<<<<<< SEARCH\n    return unique_sums.size / unique_diffs.size if unique_diffs.size > 0 else -1.0\n=======\n    return unique_sums.size / unique_diffs.size if unique_diffs.size > 0 else -1.0\n\n# Cached wrapper for compute_ratio to avoid redundant computations\n@functools.lru_cache(maxsize=100000)\ndef compute_ratio(A_tuple, B_tuple):\n    \"\"\"\n    Cached compute_ratio to avoid redundant computations on identical proposals.\n    Accepts full-array tuples for caching.\n    \"\"\"\n    A_arr = np.array(A_tuple, dtype=int)\n    B_arr = np.array(B_tuple, dtype=int)\n    return _compute_ratio(A_arr, B_arr)\n>>>>>>> REPLACE\n\n5) Finally, update the two places in `main()` where you call `compute_ratio` so they now pass in tuples of the arrays, which match the cache key:\n\n<<<<<<< SEARCH\n    best_ratio = compute_ratio(A_ind, B_ind)\n=======\n    best_ratio = compute_ratio(tuple(A_ind), tuple(B_ind))\n>>>>>>> REPLACE\n\nand\n\n<<<<<<< SEARCH\n        ratio = compute_ratio(C_ind, D_ind)\n=======\n        ratio = compute_ratio(tuple(C_ind), tuple(D_ind))\n>>>>>>> REPLACE\n\nExplanation of benefits:\n\n- By renaming your original to `_compute_ratio` and wrapping it in an `lru_cache`, any identical proposals will skip the expensive outer\u2010product + `unique` logic after the first evaluation.\n- Calling `compute_ratio` with `tuple(...)` means the cache key is the full bit\u2010pattern; collisions are rare, and cache hits will be extremely fast.\n- Switching to `np.flatnonzero` is purely stylistic but slightly more concise/readable."]}}}