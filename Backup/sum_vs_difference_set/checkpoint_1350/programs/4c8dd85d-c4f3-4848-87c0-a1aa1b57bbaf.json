{"id": "4c8dd85d-c4f3-4848-87c0-a1aa1b57bbaf", "code": "import numpy as np\n\n# For reproducibility, use NumPy\u2019s Generator\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    # Use support\u2010based sums/differences for sparse vectors\n    a_pos = np.nonzero(A_ind)[0]\n    b_pos = np.nonzero(B_ind)[0]\n    # early exit on empty sets\n    if a_pos.size == 0 or b_pos.size == 0:\n        return -1\n    # compute sum\u2010set and difference\u2010set via broadcasting + unique\n    sums  = np.unique(a_pos[:, None] + b_pos[None, :])\n    diffs = np.unique(a_pos[:, None] - b_pos[None, :])\n    sizeS = sums.size\n    sizeD = diffs.size\n    return sizeS / sizeD if sizeD > 0 else -1\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind = A_ind.copy()\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # helper to do a balanced add/remove on one indicator vector\n    def flip_bit(ind):\n        ones = np.flatnonzero(ind)\n        zeros = np.flatnonzero(ind == 0)\n        if len(ones) > 1 and rng.random() < 0.5:\n            idx = rng.choice(ones)\n            ind[idx] = 0\n        elif len(zeros) > 0:\n            idx = rng.choice(zeros)\n            ind[idx] = 1\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    visited = set()\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if rng.random() < 0.5 else D_ind)\n\n        # now skip any pair we've already evaluated (track the proposal, not the best)\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip any invalid\u2010difference proposals right away\n        if ratio == -1:\n            continue\n        if ratio > best_ratio:\n            best_ratio = ratio\n            best_A, best_B = C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: Hybrid Evolutionary and Theoretically-Informed Local Search for Enhanced Discovery of MSTD Pairings\n\nAbstract:  \nThe existing local\u2010search algorithm for identifying pairs of 0/1-indicator vectors (A,B) that maximize the sum\u2010to\u2010difference ratio suffers from (i) frequent invalid (zero-difference) proposals yielding an \u201cerror = -1,\u201d (ii) search stagnation and poor exploration, and (iii) high per\u2010iteration cost due to full convolution and cross\u2010correlation. We propose a novel, implementable framework that integrates insights from successful evolutionary heuristics and structured constructions of More-Sums-Than-Differences (MSTD) sets:\n\n1. Hybrid Genetic\u2013Hill\u2010Climbing Strategy  \n   \u2022 Encode candidate pairs (A,B) as concatenated bitstrings.  \n   \u2022 Employ population\u2010based evolution with crossover and mutation to explore diverse regions.  \n   \u2022 Apply adaptive local flips\u2014guided by dynamic penalty gradients\u2014to refine offspring and escape local optima.\n\n2. Incremental Convolution Updates  \n   \u2022 Maintain running counts of sumset and difference\u2010set supports under single\u2010bit flips.  \n   \u2022 Update sizeS and sizeD in O(n) time per move, avoiding repeated full convolutions and enabling millions of evaluations within practical time limits.\n\n3. Continuous Surrogate Penalization  \n   \u2022 Replace hard rejection of zero-difference candidates with a smoothly decaying penalty term.  \n   \u2022 Define fitness F(A,B) = sizeS/sizeD \u2212 \u03bb\u00b7exp(\u2212\u03b1\u00b7sizeD), ensuring a non-degenerate gradient toward valid high\u2010ratio solutions.\n\n4. Theory-Driven Seeding  \n   \u2022 Initialize the population with known structured MSTD families (e.g., fringed X-sets and their scaled translations).  \n   \u2022 Introduce controlled random perturbations to these seeds, preserving theoretical guarantees while encouraging novel discoveries.\n\nEvaluation will be conducted on N = 30, 50, and 100 with budgets up to 10^6 function evaluations. Metrics include maximal sum\u2010to\u2010difference ratio, convergence rate, and population diversity. We anticipate that this hybrid approach will substantially reduce invalid proposals, accelerate convergence to high\u2010ratio MSTD pairs, and yield new constructions beyond classical examples."], "idea_reward": 6.67, "parent_id": "45269897-faa9-4afb-9903-5c60c77eb395_migrant_4", "generation": 7, "timestamp": 1757775975.6118026, "iteration_found": 275, "metrics": {"error": -1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 9 lines with 13 lines\nChange 2: Replace 9 lines with 8 lines", "parent_metrics": {"error": -1.0}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \n\n\n# Previous Program:\n```python\nimport numpy as np\n\n# For reproducibility, use NumPy\u2019s Generator\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    # Explicit full convolution for the sum\u2010set\n    S = np.convolve(A_ind, B_ind, mode='full')\n    sizeS = np.count_nonzero(S)\n    # Full cross\u2010correlation for the difference\u2010set\n    D = np.correlate(A_ind, B_ind, mode='full')\n    sizeD = np.count_nonzero(D)\n    # Return ratio (or -1 when invalid)\n    return sizeS / sizeD if sizeD > 0 else -1\n\ndef main():\n    N = 30\n    # Initialize with Conway MSTD set\n    init = [0, 2, 3, 4, 7, 11, 12, 14]\n    A_ind = np.zeros(N, dtype=int)\n    A_ind[init] = 1\n    B_ind = A_ind.copy()\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n\n    # helper to do a balanced add/remove on one indicator vector\n    def flip_bit(ind):\n        ones = np.flatnonzero(ind)\n        zeros = np.flatnonzero(ind == 0)\n        if len(ones) > 1 and rng.random() < 0.5:\n            idx = rng.choice(ones)\n            ind[idx] = 0\n        elif len(zeros) > 0:\n            idx = rng.choice(zeros)\n            ind[idx] = 1\n\n    # Local search: random single\u2010bit flips\n    max_iter = 20000\n    visited = set()\n    for _ in range(max_iter):\n        C_ind = best_A.copy()\n        D_ind = best_B.copy()\n\n        # skip any pair we've already evaluated\n        # use bytes key for faster state hashing and lower memory overhead\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if rng.random() < 0.5 else D_ind)\n\n        ratio = compute_ratio(C_ind, D_ind)\n        # skip any invalid\u2010difference proposals right away\n        if ratio == -1:\n            continue\n        if ratio > best_ratio:\n            best_ratio = ratio\n            best_A, best_B = C_ind.copy(), D_ind.copy()\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- error: -1.0000\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: error. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.4138\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.4138\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.4828\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4828)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check on non-empty sets\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.4828)\n\n\n### Program 2 (Score: -1.0000)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nrng = default_rng(42)\n# Use numpy RNG for flips instead of Python's random\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind, B_ind):\n    \"\"\"\n    Compute the sum-to-difference ratio R(A,B) = |A+B| / |A-B|.\n    Return -1 if denominator is zero.\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n### Program 3 (Score: 1.2105)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.2105)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n# Global cache for computed ratios to avoid redundant convolution/correlation\n# ... (truncated)\n```\nKey features: Alternative approach to error\n\n\n### Program D2 (Score: -1.0000)\n```python\nimport numpy as np\n# Use numpy default_rng for reproducibility and better performance\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# ... (truncated)\n```\nKey features: Alternative approach to error\n\n\n# Current Proposal\nTitle: Hybrid Evolutionary and Theoretically-Informed Local Search for Enhanced Discovery of MSTD Pairings\n\nAbstract:  \nThe existing local\u2010search algorithm for identifying pairs of 0/1-indicator vectors (A,B) that maximize the sum\u2010to\u2010difference ratio suffers from (i) frequent invalid (zero-difference) proposals yielding an \u201cerror = -1,\u201d (ii) search stagnation and poor exploration, and (iii) high per\u2010iteration cost due to full convolution and cross\u2010correlation. We propose a novel, implementable framework that integrates insights from successful evolutionary heuristics and structured constructions of More-Sums-Than-Differences (MSTD) sets:\n\n1. Hybrid Genetic\u2013Hill\u2010Climbing Strategy  \n   \u2022 Encode candidate pairs (A,B) as concatenated bitstrings.  \n   \u2022 Employ population\u2010based evolution with crossover and mutation to explore diverse regions.  \n   \u2022 Apply adaptive local flips\u2014guided by dynamic penalty gradients\u2014to refine offspring and escape local optima.\n\n2. Incremental Convolution Updates  \n   \u2022 Maintain running counts of sumset and difference\u2010set supports under single\u2010bit flips.  \n   \u2022 Update sizeS and sizeD in O(n) time per move, avoiding repeated full convolutions and enabling millions of evaluations within practical time limits.\n\n3. Continuous Surrogate Penalization  \n   \u2022 Replace hard rejection of zero-difference candidates with a smoothly decaying penalty term.  \n   \u2022 Define fitness F(A,B) = sizeS/sizeD \u2212 \u03bb\u00b7exp(\u2212\u03b1\u00b7sizeD), ensuring a non-degenerate gradient toward valid high\u2010ratio solutions.\n\n4. Theory-Driven Seeding  \n   \u2022 Initialize the population with known structured MSTD families (e.g., fringed X-sets and their scaled translations).  \n   \u2022 Introduce controlled random perturbations to these seeds, preserving theoretical guarantees while encouraging novel discoveries.\n\nEvaluation will be conducted on N = 30, 50, and 100 with budgets up to 10^6 function evaluations. Metrics include maximal sum\u2010to\u2010difference ratio, convergence rate, and population diversity. We an...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Below are two targeted diffs to (1) correct the visited\u2010set logic so that we avoid revisiting *proposed* states rather than always skipping on the *current best*, and (2) speed up `compute_ratio` for sparse indicator vectors by working on their support sets instead of full convolutions. Together these should greatly increase the number of distinct proposals evaluated and reduce per\u2010call cost of the ratio:\n\n<<<<<<< SEARCH\ndef compute_ratio(A_ind, B_ind):\n    # Explicit full convolution for the sum\u2010set\n    S = np.convolve(A_ind, B_ind, mode='full')\n    sizeS = np.count_nonzero(S)\n    # Full cross\u2010correlation for the difference\u2010set\n    D = np.correlate(A_ind, B_ind, mode='full')\n    sizeD = np.count_nonzero(D)\n    # Return ratio (or -1 when invalid)\n    return sizeS / sizeD if sizeD > 0 else -1\n=======\ndef compute_ratio(A_ind, B_ind):\n    # Use support\u2010based sums/differences for sparse vectors\n    a_pos = np.nonzero(A_ind)[0]\n    b_pos = np.nonzero(B_ind)[0]\n    # early exit on empty sets\n    if a_pos.size == 0 or b_pos.size == 0:\n        return -1\n    # compute sum\u2010set and difference\u2010set via broadcasting + unique\n    sums  = np.unique(a_pos[:, None] + b_pos[None, :])\n    diffs = np.unique(a_pos[:, None] - b_pos[None, :])\n    sizeS = sums.size\n    sizeD = diffs.size\n    return sizeS / sizeD if sizeD > 0 else -1\n>>>>>>> REPLACE\n\nExplanation: for small, sparse indicator vectors this avoids an O(N) convolution in C and replaces it with an O(k\u00b2) broadcast + unique on k = popcount, which in practice is much faster when k\u226aN.\n\n---\n\n<<<<<<< SEARCH\n        # skip any pair we've already evaluated\n        # use bytes key for faster state hashing and lower memory overhead\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if rng.random() < 0.5 else D_ind)\n=======\n        # propose a balanced add/remove move for A or B (refactored)\n        flip_bit(C_ind if rng.random() < 0.5 else D_ind)\n\n        # now skip any pair we've already evaluated (track the proposal, not the best)\n        key = (C_ind.tobytes(), D_ind.tobytes())\n        if key in visited:\n            continue\n        visited.add(key)\n>>>>>>> REPLACE\n\nExplanation: moving the visited\u2010set check to *after* the flip ensures we are marking and skipping *proposed* (A,B) states\u2014otherwise the original code effectively only allowed one iteration per new best and threw away the rest.\n\nThese two changes together should greatly increase the number of unique proposals evaluated per run and reduce the per\u2010iteration cost of the ratio computation."]}}}