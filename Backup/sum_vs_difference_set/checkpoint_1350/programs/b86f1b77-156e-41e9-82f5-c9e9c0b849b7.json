{"id": "b86f1b77-156e-41e9-82f5-c9e9c0b849b7", "code": "import numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Removed caching to reduce per\u2010call overhead\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check for empty sets\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    return -1.0 if num_diffs == 0 else num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray, ones: np.ndarray, zeros: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move using precomputed one- and zero-indices.\"\"\"\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # use boolean arrays for lighter\u2010weight, faster bit\u2010ops\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9999        # even slower cooling to escape local optima\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    # Pre-bind heavy functions once per outer loop\n    _compute_ratio = compute_ratio\n    _rand        = rng_random\n    _exp         = exp\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        # Precompute indices once per outer iteration\n        ones_A = flatnonzero_fn(current_A)\n        zeros_A = flatnonzero_fn(~current_A)\n        ones_B = flatnonzero_fn(current_B)\n        zeros_B = flatnonzero_fn(~current_B)\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n            else:\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or _rand() < _exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n", "language": "python", "proposal": ["Title: A Multi-Population Surrogate-Guided Evolutionary Framework with Learned Proposal Distributions for Maximizing Sum-to-Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address the sub-optimal convergence (score \u22481.5455), local-optima stagnation, and high per-evaluation cost of current hill-climbing and simulated-annealing methods for maximizing the sum-to-difference ratio |A+B|/|A\u2212B| over 0/1 indicator vectors. Building on recent successes in surrogate-assisted search, population diversity maintenance, and reinforcement learning for move proposals, we propose a novel, implementable framework that integrates:\n\n1. Surrogate-Accelerated Screening  \n   \u2022 Train a lightweight neural surrogate on summary statistics (marginal counts, auto- and cross-correlation histograms) to predict ratio improvements.  \n   \u2022 Use the surrogate to pre-filter large batches of candidate moves, evaluating only the top-K via exact GPU-accelerated convolution/correlation.\n\n2. Multi-Population Evolutionary Search  \n   \u2022 Maintain multiple subpopulations evolving in parallel under distinct operator policies (single-swap, multi-swap, block shuffle).  \n   \u2022 Employ a multi-armed bandit meta-controller to adaptively allocate compute budget to the most promising subpopulations and operators.  \n   \u2022 Periodically migrate elite individuals across subpopulations to enhance global exploration.\n\n3. Learned Proposal Distributions  \n   \u2022 Formulate mutation operator selection as a contextual bandit problem, using per-bit \u201cimportance scores\u201d learned via policy-gradient updates from surrogate feedback.  \n   \u2022 Bias swaps toward bit positions with historically high impact on ratio gains.\n\n4. Dynamic Temperature and Restart Mechanisms  \n   \u2022 Replace fixed cooling schedules with adaptive temperature control that increases temperature upon convergence plateaus, measured by population diversity metrics.  \n   \u2022 Trigger controlled random-restarts from elite archives to avoid deep local traps.\n\n5. GPU-Accelerated Exact Evaluations  \n   \u2022 Leverage cuFFT and tensor-core\u2013optimized kernels to compute convolution/correlation ratios up to 10\u00d7 faster for dimensions N\u226550, enabling real-time hyperparameter sweeps.\n\nIn extensive experiments on N=30\u2013200 indicator sets, our framework is expected to achieve (i) 40\u201360% faster convergence to high-quality solutions (target ratio \u22651.8) under fixed budgets, (ii) superior final ratios (\u22651.85) through enhanced exploration, and (iii) sublinear scaling via parallel GPU acceleration. We outline a four-phase implementation plan\u2014surrogate development, evolutionary integration, GPU kernel optimization, and ablation studies\u2014to validate each component\u2019s contribution and ensure robust, end-to-end performance gains."], "idea_reward": 5.75, "parent_id": "d77dd970-31da-4084-bf82-e39b0985e10f", "generation": 20, "timestamp": 1757825561.2197783, "iteration_found": 1290, "metrics": {"score": 1.5454545454545454}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 16 lines with 14 lines\nChange 2: Replace 17 lines with 22 lines", "parent_metrics": {"score": 1.5454545454545454}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert software developer tasked with iteratively improving a codebase.\nYour job is to analyze the current program and suggest improvements based on feedback from previous attempts.\nFocus on making targeted changes that will increase the program's performance metrics.\n", "user": "# Previous Proposal: \nTitle: A Hybrid Evolutionary-Surrogate Framework for Maximizing Sum\u2010to\u2010Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address key limitations of existing hill\u2010climbing and simulated\u2010annealing methods for maximizing the sum-to-difference ratio |A+B|/|A\u2212B| over 0/1 indicator vectors: slow convergence, vulnerability to local optima, and high per\u2010evaluation cost. Building on successful elements of batch proposal schemes and adaptive cooling, we propose a novel, implementable framework that combines evolutionary search, learned surrogate models, and GPU\u2010accelerated ratio estimation.\n\n1. Identified Weaknesses  \n\u2022 Local\u2010optima stagnation under simple bit\u2010swap proposals and single\u2010chain annealing schedules.  \n\u2022 High computational overhead from repeated full convolutions and correlations in ratio evaluations.  \n\u2022 Limited diversity in proposals due to fixed\u2010size batch sampling from the current state.\n\n2. Technical Innovations  \n\u2022 Surrogate\u2010Accelerated Evaluation: Train a lightweight neural or Gaussian\u2010process surrogate to predict the sum\u2010to\u2010difference ratio from low\u2010dimensional summary statistics of (A,B). Use the surrogate to pre\u2010screen candidate moves, invoking the exact conv/corr only on top\u2010K proposals per batch.  \n\u2022 Multi\u2010Population Evolutionary Scheme: Maintain multiple subpopulations of (A,B) vectors evolving in parallel, each using specialized mutation operators (1-swap, 2-swap, block exchange). Periodically exchange elite individuals across populations to escape local traps.  \n\u2022 Adaptive Proposal Distribution: Instead of uniform random swaps, learn a per\u2010bit importance weight via reinforcement\u2010learning\u2013style credit assignment, biasing moves towards positions historically contributing most to ratio improvements.  \n\u2022 GPU\u2010Accelerated Convolutions: Implement convolution/correlation ratio computation using cuFFT or tensor\u2010core\u2013optimized dot\u2010products, reducing per\u2010evaluation latency by up to 10\u00d7 for large N.  \n\u2022 Dynamic Cooling and Restart Strategies: Replace fix...(truncated)\n\n# Previous Program:\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Removed caching to reduce per\u2010call overhead\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\nrng_random = rng.random\nrng_choice = rng.choice\nexp = math.exp\ncnz = np.count_nonzero\nany_fn = np.any\nflatnonzero_fn = np.flatnonzero\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute sum\u2010to\u2010difference ratio |A+B|/|A\u2212B|. Return \u22121.0 if infeasible.\"\"\"\n    # quick check for empty sets\n    if not any_fn(A_ind) or not any_fn(B_ind):\n        return -1.0\n    num_sums = cnz(convolve_fn(A_ind, B_ind))\n    num_diffs = cnz(correlate_fn(A_ind, B_ind, mode='full'))\n    return -1.0 if num_diffs == 0 else num_sums / num_diffs\n\n# Helper: perform one balanced swap/add/remove on a boolean indicator array\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = flatnonzero_fn(ind)\n    zeros = flatnonzero_fn(1 - ind)\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = 0\n            ind[adds] = 1\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = 0\n            ind[i_add] = 1\n    return ind\n\n# Configuration constants\nDEFAULT_N = 30\nCONWAY_MSTD_INIT = [0, 2, 3, 4, 7, 11, 12, 14]\nBATCH_SIZE = 20  # increased number of local proposals for better exploration\n\ndef main(N: int = DEFAULT_N) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Perform hill\u2010climbing search starting from the Conway MSTD set of size N.\"\"\"\n    # use boolean arrays for lighter\u2010weight, faster bit\u2010ops\n    A_ind = np.zeros(N, dtype=bool)\n    B_ind = np.zeros(N, dtype=bool)\n    A_ind[CONWAY_MSTD_INIT] = 1\n    B_ind[:] = A_ind\n\n    # Evaluate initial ratio\n    best_ratio = compute_ratio(A_ind, B_ind)\n    best_A, best_B = A_ind.copy(), B_ind.copy()\n    # Initialize simulated annealing\n    current_A, current_B = best_A.copy(), best_B.copy()\n    current_ratio = best_ratio\n    T = 1.0\n    decay = 0.9999        # even slower cooling to escape local optima\n\n    # Local search: random single\u2010bit flips\n    max_iter = 50000  # extended search iterations for improved convergence\n    # Pre-bind heavy functions once per outer loop\n    _compute_ratio = compute_ratio\n    _rand        = rng_random\n    _exp         = exp\n    for _ in range(max_iter):\n        # batch multiple proposals to improve exploration\n        local_best_ratio = -1.0\n        local_best_A = None\n        local_best_B = None\n        # Use current state for generating local proposals to enhance search diversity\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind)\n                D_ind = propose_move(D_ind)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind)\n            else:\n                D_ind = propose_move(D_ind)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n        # simulated annealing acceptance\n        delta = local_best_ratio - current_ratio\n        if delta > 0 or _rand() < _exp(delta / T):\n            current_ratio = local_best_ratio\n            current_A, current_B = local_best_A, local_best_B\n        # update global best\n        if current_ratio > best_ratio:\n            best_ratio, best_A, best_B = current_ratio, current_A, current_B\n        # cool down\n        T *= decay\n\n    print(f\"N={N}, best ratio={best_ratio:.4f}\")\n    return best_A, best_B\n\nif __name__ == \"__main__\":\n    A_ind, B_ind = main()\n    print(\"A_ind:\", A_ind)\n    print(\"B_ind:\", B_ind)\n\n```\n\n# Previous Performance Metrics: \n- score: 1.5455\n\n# Areas Identified for Improvement: \n- Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: score: 1.5588\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n# Pre\u2010bind exponential for simulated\u2010annealing checks\nexp = math.exp\n\nimport functools\n\nrng = default_rng(42)\nrng_random = rng.random\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 2 (Score: 1.5588)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\nimport math\n\n# Prebind convolution and correlation functions for speed\nconvolve_fn = np.convolve\ncorrelate_fn = np.correlate\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated for brevity)\n```\nKey features: Performs well on score (1.5588)\n\n\n### Program 3 (Score: -1.0000)\n```python\nimport numpy as np\n\n# For reproducibility\nrng = np.random.default_rng(42)\n\n# Compute the sum\u2010to\u2010difference ratio for two 0/1 indicator vectors\n# now explicitly count unique sums and differences\ndef compute_ratio(A_ind: np.ndarray, B_ind: np.ndarray) -> float:\n    \"\"\"Compute the sum-to-difference ratio R(A, B) = |A+B| / |A\u2212B|.\n    Return -1.0 if the denominator is zero (invalid).\"\"\"\n# ... (truncated for brevity)\n```\nKey features: Performs well on error (-1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.2143)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n### Program D2 (Score: 1.4324)\n```python\nimport numpy as np\nfrom numpy.random import default_rng\n\n# For reproducibility\nrng = default_rng(42)\n# ... (truncated)\n```\nKey features: Alternative approach to score\n\n\n# Current Proposal\nTitle: A Multi-Population Surrogate-Guided Evolutionary Framework with Learned Proposal Distributions for Maximizing Sum-to-Difference Ratios in Binary Indicator Sets\n\nAbstract:\nWe address the sub-optimal convergence (score \u22481.5455), local-optima stagnation, and high per-evaluation cost of current hill-climbing and simulated-annealing methods for maximizing the sum-to-difference ratio |A+B|/|A\u2212B| over 0/1 indicator vectors. Building on recent successes in surrogate-assisted search, population diversity maintenance, and reinforcement learning for move proposals, we propose a novel, implementable framework that integrates:\n\n1. Surrogate-Accelerated Screening  \n   \u2022 Train a lightweight neural surrogate on summary statistics (marginal counts, auto- and cross-correlation histograms) to predict ratio improvements.  \n   \u2022 Use the surrogate to pre-filter large batches of candidate moves, evaluating only the top-K via exact GPU-accelerated convolution/correlation.\n\n2. Multi-Population Evolutionary Search  \n   \u2022 Maintain multiple subpopulations evolving in parallel under distinct operator policies (single-swap, multi-swap, block shuffle).  \n   \u2022 Employ a multi-armed bandit meta-controller to adaptively allocate compute budget to the most promising subpopulations and operators.  \n   \u2022 Periodically migrate elite individuals across subpopulations to enhance global exploration.\n\n3. Learned Proposal Distributions  \n   \u2022 Formulate mutation operator selection as a contextual bandit problem, using per-bit \u201cimportance scores\u201d learned via policy-gradient updates from surrogate feedback.  \n   \u2022 Bias swaps toward bit positions with historically high impact on ratio gains.\n\n4. Dynamic Temperature and Restart Mechanisms  \n   \u2022 Replace fixed cooling schedules with adaptive temperature control that increases temperature upon convergence plateaus, measured by population diversity metrics.  \n   \u2022 Trigger controlled random-restarts from elite archives to avoid deep local traps.\n\n5. GPU-Accelera...(truncated)\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["Below is a pair of focused diffs that (1) simplify `propose_move` by having it take pre-computed one/zero indices, and (2) hoist the costly `flatnonzero` calls out of the inner batch loop.  This both improves readability (no more hidden index\u2010computations inside `propose_move`) and cuts down on repeated work (you only compute those index lists once per outer iteration, instead of once per proposal).\n\nPlease apply both diffs.\n\n1) Change `propose_move` signature and body:\n\n<<<<<<< SEARCH\ndef propose_move(ind: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move to maintain constant cardinality and improve exploration.\"\"\"\n    ones = flatnonzero_fn(ind)\n    zeros = flatnonzero_fn(1 - ind)\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = 0\n            ind[adds] = 1\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = 0\n            ind[i_add] = 1\n    return ind\n=======\ndef propose_move(ind: np.ndarray, ones: np.ndarray, zeros: np.ndarray) -> np.ndarray:\n    \"\"\"Perform a swap or multi-swap move using precomputed one- and zero-indices.\"\"\"\n    if ones.size and zeros.size:\n        if rng_random() < 0.3 and ones.size > 1 and zeros.size > 1:\n            removes = rng_choice(ones, size=2, replace=False)\n            adds = rng_choice(zeros, size=2, replace=False)\n            ind[removes] = False\n            ind[adds] = True\n        else:\n            i_remove = rng_choice(ones)\n            i_add = rng_choice(zeros)\n            ind[i_remove] = False\n            ind[i_add] = True\n    return ind\n>>>>>>> REPLACE\n\n2) In `main`, immediately before the `for _ in range(BATCH_SIZE)` loop, precompute `ones_A`, `zeros_A`, `ones_B`, and `zeros_B`, and pass them into `propose_move`:\n\n<<<<<<< SEARCH\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind)\n                D_ind = propose_move(D_ind)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind)\n            else:\n                D_ind = propose_move(D_ind)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n=======\n        # Precompute indices once per outer iteration\n        ones_A = flatnonzero_fn(current_A)\n        zeros_A = flatnonzero_fn(~current_A)\n        ones_B = flatnonzero_fn(current_B)\n        zeros_B = flatnonzero_fn(~current_B)\n        for _ in range(BATCH_SIZE):  # batch size configurable\n            # Generate candidate proposals by copying both state vectors once\n            C_ind, D_ind = current_A.copy(), current_B.copy()\n            r = _rand()\n            # With some probability, mutate both for deeper exploration\n            if r < 0.2:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            elif r < 0.6:\n                C_ind = propose_move(C_ind, ones_A, zeros_A)\n            else:\n                D_ind = propose_move(D_ind, ones_B, zeros_B)\n            ratio = _compute_ratio(C_ind, D_ind)\n            if ratio > local_best_ratio:\n                local_best_ratio = ratio\n                # Store best candidate references directly (no extra copies)\n                local_best_A, local_best_B = C_ind, D_ind\n>>>>>>> REPLACE\n\nExplanation:\n\n- By pulling `flatnonzero_fn` calls out of the tight inner loop, we save O(N) work per proposal and make `propose_move` simpler.\n- Passing precomputed `ones`/`zeros` arrays into `propose_move` clarifies its dependencies and removes duplicated work, giving a measurable speedup and cleaner code structure."]}}}